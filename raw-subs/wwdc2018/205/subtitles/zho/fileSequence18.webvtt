WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:17:57.444 --> 00:18:02.082 align:middle line:-1
以评估在不同医疗情况下的说话模式

00:18:02.149 --> 00:18:04.117 align:middle line:-1
包括认知和情绪

00:18:07.120 --> 00:18:12.526 align:middle line:-2
有趣的是 我们的下一个任务
是说话和听力的结合

00:18:13.861 --> 00:18:15.829 align:middle line:-1
讲话与噪音当前任务

00:18:16.597 --> 00:18:20.400 align:middle line:-1
这能让你实现完全自动化的语音测听

00:18:21.668 --> 00:18:25.639 align:middle line:-1
传统的声音测听使用纯声音

00:18:25.706 --> 00:18:27.541 align:middle line:-1
也就是记号波形

00:18:28.141 --> 00:18:29.843 align:middle line:-1
对于录好的实例

00:18:29.910 --> 00:18:32.946 align:middle line:-1
用户可以清晰地分辨纯语音

00:18:33.013 --> 00:18:35.849 align:middle line:-1
但是要分辨词语非常困难

00:18:36.049 --> 00:18:37.885 align:middle line:-1
当这些词语跟噪音混在一起的时候

00:18:38.919 --> 00:18:40.621 align:middle line:-1
这很接近于

00:18:40.687 --> 00:18:44.525 align:middle line:-1
现实世界中早期听力下降的例子

00:18:44.825 --> 00:18:47.928 align:middle line:-1
例如 在一个吵闹的餐厅里

00:18:47.995 --> 00:18:51.698 align:middle line:-2
当你不能理解
坐在你前面的人在说什么时

00:18:52.966 --> 00:18:54.902 align:middle line:-1
在我详细介绍之前

00:18:54.968 --> 00:18:58.238 align:middle line:-2
让我们来看看
这个任务是如何运作的

