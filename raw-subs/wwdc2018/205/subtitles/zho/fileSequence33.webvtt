WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:56.476 --> 00:33:01.215 align:middle line:-2
我添加了一个新的queryNewAssessments方法
我在那里调用queryTremor方法

00:33:01.281 --> 00:33:05.052 align:middle line:-2
对于给定的开始日期和结束日期
和queryDyskineticSymptom方法

00:33:05.485 --> 00:33:07.087 align:middle line:-1
为相同的开始日期和结束日期

00:33:09.456 --> 00:33:12.693 align:middle line:-2
为了这个演示 我们已经运行了
这个查询并收集震颤

00:33:12.759 --> 00:33:15.596 align:middle line:-2
以及运动障碍症状数据点
并将它们保存为JSON文件的一部分

00:33:16.029 --> 00:33:19.733 align:middle line:-2
让我们接着使用这些JSON文件
来创建ResearchKit图表

00:33:20.868 --> 00:33:22.903 align:middle line:-2
我会转到
我的图形视图控制器

00:33:23.904 --> 00:33:26.507 align:middle line:-2
在这里 如你所见
我有一个createGraph方法

00:33:26.773 --> 00:33:29.710 align:middle line:-2
它可以读取JSON文件
并从它们创建ResearchKit图表

00:33:30.277 --> 00:33:32.045 align:middle line:-2
让我们在viewDidLoad中
调用这些方法

00:33:34.381 --> 00:33:36.950 align:middle line:-1
很好 现在让我们运行它

00:33:38.685 --> 00:33:41.355 align:middle line:-2
如你所见 我们添加了
语音识别当前任务

00:33:41.855 --> 00:33:44.157 align:middle line:-1
并添加了运动障碍API

00:33:44.925 --> 00:33:46.727 align:middle line:-1
这就是我们的帕金森研究app

00:33:47.027 --> 00:33:48.295 align:middle line:-1
我们在顶部有调查问卷

00:33:48.629 --> 00:33:50.397 align:middle line:-1
让我们运行一个问卷吧

00:33:51.765 --> 00:33:55.469 align:middle line:-2
如Srinath提到的 我们拥有
一包含所有调查项目的卡片视图

00:33:56.036 --> 00:34:00.641 align:middle line:-2
所有这些ResearchKit中
的步骤都坚持了iOS规范

