WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:59.716 --> 00:23:02.296 A:middle
us this is a banana, and this is

00:23:02.296 --> 00:23:02.976 A:middle
a cup of coffee.

00:23:03.516 --> 00:23:09.500 A:middle
[ Applause ]

00:23:16.136 --> 00:23:17.886 A:middle
So let's recap what we just saw.

00:23:19.886 --> 00:23:21.756 A:middle
First, we loaded images and

00:23:21.756 --> 00:23:23.896 A:middle
annotations into SFrame format

00:23:24.146 --> 00:23:25.626 A:middle
and joined them together with a

00:23:25.626 --> 00:23:26.556 A:middle
simple function call.

00:23:27.296 --> 00:23:28.976 A:middle
We interactively explored that

00:23:28.976 --> 00:23:30.786 A:middle
data using the explore method.

00:23:31.826 --> 00:23:33.616 A:middle
We created a model just with a

00:23:33.616 --> 00:23:35.606 A:middle
simple high-level API&lt; passing

00:23:35.606 --> 00:23:37.286 A:middle
in that data object containing

00:23:37.286 --> 00:23:38.756 A:middle
both the images and the bounding

00:23:38.756 --> 00:23:39.936 A:middle
boxes and labels.

00:23:40.906 --> 00:23:42.676 A:middle
We then evaluated that model

00:23:42.836 --> 00:23:43.956 A:middle
both qualitatively,

00:23:44.026 --> 00:23:45.596 A:middle
spot-checking the output as a

00:23:45.596 --> 00:23:46.176 A:middle
human would.

00:23:46.556 --> 00:23:48.566 A:middle
And quantitatively, asking for a

00:23:48.566 --> 00:23:50.486 A:middle
specific metric that applies to

00:23:50.486 --> 00:23:51.526 A:middle
the task that we're doing.

00:23:52.326 --> 00:23:54.206 A:middle
Then we exported that model to

00:23:54.206 --> 00:23:56.886 A:middle
Core ML format for use in an

00:23:58.366 --> 00:23:58.446 A:middle
app.

00:23:58.726 --> 00:24:00.306 A:middle
Next, I'd like to switch gears

