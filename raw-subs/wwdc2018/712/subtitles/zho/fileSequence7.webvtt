WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:59.846 --> 00:07:01.196 A:middle
它使用了对象检测模型

00:07:01.746 --> 00:07:02.866 A:middle
我们想要识别

00:07:03.186 --> 00:07:04.486 A:middle
图像中的不同食物

00:07:04.726 --> 00:07:05.636 A:middle
我们需要知道它们在哪里

00:07:05.636 --> 00:07:07.046 A:middle
在图像的哪个位置

00:07:07.046 --> 00:07:08.396 A:middle
然后才能轻点它们

00:07:08.396 --> 00:07:10.000 A:middle
查看不同的卡路里数值

00:07:13.196 --> 00:07:14.636 A:middle
所以让我们来看看

00:07:14.636 --> 00:07:16.036 A:middle
创建这个机器学习模型

00:07:16.036 --> 00:07:17.846 A:middle
所需要的数据类型 00:07:18.436 --> 00:07:20.906 A:middle当然 我们需要图像

00:07:20.906 --> 00:07:21.866 A:middle
如果我们只是建立一个

00:07:21.866 --> 00:07:24.006 A:middle
简单的图像分类器模型 

00:07:24.306 --> 00:07:25.286 A:middle
那我们只需要一套图像

00:07:25.286 --> 00:07:28.356 A:middle
和描述图像的标签

00:07:29.366 --> 00:07:30.506 A:middle
但是因为我们要进行

00:07:30.746 --> 00:07:32.506 A:middle
对象检测

00:07:32.506 --> 00:07:33.316 A:middle
我们需要更多信息

00:07:33.956 --> 00:07:35.416 A:middle
我们不仅需要了解

00:07:35.416 --> 00:07:36.226 A:middle
图像中有什么

00:07:36.496 --> 00:07:37.766 A:middle
还有那些物体在哪里

00:07:38.146 --> 00:07:40.126 A:middle
现在 如果我们仔细看一个例子

00:07:40.126 --> 00:07:42.596 A:middle
可以看到红色框圈出了

00:07:42.646 --> 00:07:43.756 A:middle
一杯咖啡

00:07:44.616 --> 00:07:46.376 A:middle
绿色框圈出了羊角面包

00:07:47.336 --> 00:07:48.916 A:middle
我们称这些方框为边界框

00:07:48.916 --> 00:07:50.996 A:middle
并用 JSON 格式

00:07:50.996 --> 00:07:51.936 A:middle
写出来

00:07:52.296 --> 00:07:53.806 A:middle
设置一个标签

00:07:53.806 --> 00:07:56.086 A:middle
然后写出 x y 坐标 宽度和高度

00:07:56.656 --> 00:07:58.186 A:middle
其中 x 和 y 坐标指的是

00:07:58.186 --> 00:07:59.926 A:middle
该边界框的中心

