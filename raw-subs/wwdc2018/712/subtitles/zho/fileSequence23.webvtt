WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:22:59.716 --> 00:23:02.976 A:middle
这是一根香蕉 这是一杯咖啡

00:23:03.516 --> 00:23:09.500 A:middle
[ 掌声 ]

00:23:16.136 --> 00:23:17.886 A:middle
所以让我们回顾一下刚刚的内容

00:23:19.886 --> 00:23:21.756 A:middle
首先 我们以 SFrame 格式

00:23:21.756 --> 00:23:23.896 A:middle
加载图像和注释

00:23:24.146 --> 00:23:25.626 A:middle
并调用简单的函数

00:23:25.626 --> 00:23:26.556 A:middle
把它们连接起来

00:23:27.296 --> 00:23:28.976 A:middle
我们使用 .explore 方法

00:23:28.976 --> 00:23:30.786 A:middle
交互式探索数据

00:23:31.826 --> 00:23:33.616 A:middle
我们创建了一个模型

00:23:33.616 --> 00:23:35.606 A:middle
仅仅是通过简单的高级 API 

00:23:35.606 --> 00:23:37.286 A:middle
传入包含图像

00:23:37.286 --> 00:23:39.936 A:middle
边界框和标签的数据对象

00:23:40.906 --> 00:23:42.676 A:middle
然后我们评估了这个模型

00:23:42.836 --> 00:23:43.956 A:middle
既进行了量化评估

00:23:44.026 --> 00:23:45.596 A:middle
又进行了模仿人类的

00:23:45.596 --> 00:23:46.176 A:middle
抽样输出检查

00:23:46.556 --> 00:23:48.566 A:middle
并得出了一个

00:23:48.566 --> 00:23:50.486 A:middle
适用于所做任务的

00:23:50.486 --> 00:23:51.526 A:middle
量化衡量标准

00:23:52.326 --> 00:23:54.206 A:middle
然后我们将该模型导出为

00:23:54.206 --> 00:23:58.446 A:middle
Core ML 格式 在 App 中使用

00:23:58.726 --> 00:24:00.306 A:middle
接下来 我想换个话题

