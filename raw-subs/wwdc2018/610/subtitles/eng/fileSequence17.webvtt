WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:59.436 --> 00:17:00.716 A:middle
point cloud and the camera

00:17:00.796 --> 00:17:01.416 A:middle
trajectory.

00:17:02.826 --> 00:17:04.106 A:middle
Have you noticed the update?

00:17:04.556 --> 00:17:05.506 A:middle
Let me show you, once more.

00:17:05.996 --> 00:17:10.866 A:middle
This update aligns the ARKit

00:17:10.866 --> 00:17:12.175 A:middle
knowledge with your real

00:17:12.286 --> 00:17:15.016 A:middle
physical world, and also, the

00:17:15.016 --> 00:17:17.536 A:middle
camera movement and results in

00:17:17.536 --> 00:17:19.425 A:middle
the better augmentation for the

00:17:19.425 --> 00:17:20.626 A:middle
coming camera frames.

00:17:21.955 --> 00:17:23.306 A:middle
By the way, all those

00:17:23.306 --> 00:17:24.935 A:middle
computations of World Tracking,

00:17:25.435 --> 00:17:27.425 A:middle
and also, all this information

00:17:27.425 --> 00:17:28.886 A:middle
about your learned environment,

00:17:29.346 --> 00:17:31.076 A:middle
everything is done on your

00:17:31.076 --> 00:17:31.996 A:middle
device only.

00:17:32.136 --> 00:17:33.496 A:middle
And all this information, also,

00:17:33.496 --> 00:17:35.096 A:middle
stays on your device only.

00:17:35.096 --> 00:17:37.836 A:middle
So, how can you use this complex

00:17:37.836 --> 00:17:40.566 A:middle
technology, now, in your app?

00:17:41.926 --> 00:17:45.606 A:middle
It is actually quite simple.

00:17:45.716 --> 00:17:47.486 A:middle
To run World Tracking you just

00:17:47.526 --> 00:17:49.766 A:middle
configure your ARSession with an

00:17:49.816 --> 00:17:51.896 A:middle
ARWorldTrackingConfiguration.

00:17:52.976 --> 00:17:55.376 A:middle
Again, its results are retuned

00:17:55.376 --> 00:17:57.336 A:middle
in an ARCamera object of the

00:17:57.336 --> 00:17:57.956 A:middle
ARFrame.

