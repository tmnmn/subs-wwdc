WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:10:58.796 --> 00:11:00.636 A:middle
因为它们对环境

00:11:00.636 --> 00:11:02.236 A:middle
的观察角度有细微的差别

00:11:02.606 --> 00:11:04.706 A:middle
这个差别能让画面更立体

00:11:04.816 --> 00:11:06.056 A:middle
更有深度感

00:11:07.106 --> 00:11:08.406 A:middle
这就是 ARKit 在处理

00:11:08.406 --> 00:11:10.176 A:middle
三角测量时

00:11:10.176 --> 00:11:12.076 A:middle
对于同一相机

00:11:12.076 --> 00:11:14.156 A:middle
不同角度的处理方式

00:11:14.736 --> 00:11:16.206 A:middle
只要画面中有足够的视觉差

00:11:16.256 --> 00:11:18.046 A:middle
ARKit 就能运行这一功能

00:11:18.896 --> 00:11:20.786 A:middle
它能够计算这些

00:11:20.786 --> 00:11:23.306 A:middle
匹配特征之间的深度数据

00:11:23.706 --> 00:11:26.826 A:middle
换句话说 这些图像中的 2D 特征

00:11:26.826 --> 00:11:29.316 A:middle
通过 3D 方式获得重组

00:11:30.806 --> 00:11:32.066 A:middle
但是 这个重组

00:11:32.066 --> 00:11:34.476 A:middle
成功的关键

00:11:35.706 --> 00:11:37.536 A:middle
在于相机位置的

00:11:37.676 --> 00:11:39.776 A:middle
改变以提供

00:11:39.776 --> 00:11:41.316 A:middle
足够的视觉差

00:11:42.356 --> 00:11:44.626 A:middle
比如说 往某一侧倾斜的运动

00:11:44.966 --> 00:11:47.746 A:middle
单纯的旋转并不能为重组

00:11:47.746 --> 00:11:48.856 A:middle
提供足够的信息

00:11:50.536 --> 00:11:52.606 A:middle
这就是有关你所身处环境的

00:11:52.606 --> 00:11:53.646 A:middle
第一份小地图

00:11:53.646 --> 00:11:55.826 A:middle
在 ARKit 中 我们将它称为

00:11:55.906 --> 00:11:56.136 A:middle
世界地图

00:11:57.396 --> 00:11:59.826 A:middle
与此同时 你的镜头的

00:11:59.826 --> 00:12:01.626 A:middle
相机位置以及

