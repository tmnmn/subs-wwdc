WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

01:02:58.986 --> 01:03:01.976 A:middle
如果我重新运行这个 App

01:03:02.046 --> 01:03:04.196 A:middle
它就会将这个新的模型

01:03:04.346 --> 01:03:05.026 A:middle
绑定到 App 中

01:03:05.696 --> 01:03:07.276 A:middle
我们可以对它进行测试

01:03:07.346 --> 01:03:08.806 A:middle
看看它是否能够正确地预测

01:03:09.176 --> 01:03:10.626 A:middle
我们训练过的图片

01:03:10.626 --> 01:03:13.116 A:middle
或者同样类型的

01:03:13.116 --> 01:03:13.806 A:middle
花的新图片

01:03:14.376 --> 01:03:16.146 A:middle
的确 它可以正确地

01:03:16.146 --> 01:03:17.416 A:middle
对玫瑰进行分类

01:03:18.366 --> 01:03:19.546 A:middle
让我们再试试朱槿的分类

01:03:19.546 --> 01:03:22.006 A:middle
经过我们的训练

01:03:22.006 --> 01:03:23.346 A:middle
以及与 App 的整合后

01:03:23.346 --> 01:03:25.703 A:middle
它也可以正确地分辨这类图片

01:03:25.996 --> 01:03:27.366 A:middle
正如你们所看到的

01:03:27.366 --> 01:03:29.536 A:middle
我们已经能够

01:03:29.536 --> 01:03:31.676 A:middle
通过 Swift 和 Xcode

01:03:31.786 --> 01:03:33.056 A:middle
在很少的时间内

01:03:33.286 --> 01:03:37.536 A:middle
用 Create ML 训练我们的分类器模型 且模型的

01:03:37.726 --> 01:03:38.036 A:middle
大小十分轻量

01:03:38.816 --> 01:03:39.746 A:middle
下面有请 John

01:03:40.516 --> 01:03:43.296 A:middle
[ 掌声 ]

01:03:43.796 --> 01:03:44.146 A:middle
&gt;&gt; 谢谢 Lizzie

01:03:47.296 --> 01:03:49.106 A:middle
这难道不酷吗

01:03:49.106 --> 01:03:50.496 A:middle
仅仅使用三行的 Swift

01:03:50.496 --> 01:03:52.776 A:middle
就在 Mac 上用几秒钟的时间

01:03:53.066 --> 01:03:57.176 A:middle
训练了一个自定义图像分类器

01:03:57.386 --> 01:03:59.836 A:middle
我们已经讨论了新的

01:03:59.836 --> 01:04:01.446 A:middle
视觉和自然语言处理 API

