WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:53:59.516 --> 00:54:04.276 A:middle
[ Applause ]

00:54:04.776 --> 00:54:06.196 A:middle
So let's see what's new for face

00:54:06.196 --> 00:54:07.736 A:middle
tracking in ARKit 2.

00:54:08.736 --> 00:54:11.106 A:middle
We added gaze tracking that will

00:54:11.106 --> 00:54:12.826 A:middle
track the left and the right eye

00:54:12.966 --> 00:54:15.326 A:middle
both in six degrees of freedom.

00:54:16.516 --> 00:54:21.046 A:middle
[ Applause ]

00:54:21.546 --> 00:54:22.646 A:middle
You will find these properties

00:54:22.646 --> 00:54:24.956 A:middle
as members of ARFaceAnchor as

00:54:24.956 --> 00:54:26.516 A:middle
well as a look-at point, this

00:54:26.516 --> 00:54:28.346 A:middle
corresponds to reintersection of

00:54:28.346 --> 00:54:29.316 A:middle
the two gaze directions.

00:54:30.326 --> 00:54:32.256 A:middle
You may use this information to

00:54:32.296 --> 00:54:34.076 A:middle
animate again your own character

00:54:34.496 --> 00:54:36.456 A:middle
or of any other form of input to

00:54:36.456 --> 00:54:36.796 A:middle
your app.

00:54:36.796 --> 00:54:38.446 A:middle
And there's more.

00:54:39.716 --> 00:54:40.816 A:middle
We added support for tongue,

00:54:42.176 --> 00:54:43.186 A:middle
which comes in the form of a new

00:54:43.186 --> 00:54:43.746 A:middle
blend shape.

00:54:44.636 --> 00:54:45.566 A:middle
This blend shape will assume a

00:54:45.566 --> 00:54:47.786 A:middle
value of 1 if my tongue is out 0

00:54:48.096 --> 00:54:48.516 A:middle
if not.

00:54:49.516 --> 00:54:51.276 A:middle
Again, you could use this to

00:54:51.276 --> 00:54:53.086 A:middle
animate your own character or

00:54:53.086 --> 00:54:55.896 A:middle
use this as a form of input to

00:54:55.896 --> 00:54:56.946 A:middle
your app.

