WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:55:00.636 --> 00:55:01.086 A:middle
Thank you.

00:55:01.821 --> 00:55:03.821 A:middle
[ Applause ]

00:55:04.126 --> 00:55:05.216 A:middle
So seeing myself sticking my

00:55:05.216 --> 00:55:06.766 A:middle
tongue out over and over is a

00:55:06.766 --> 00:55:07.936 A:middle
good time for summary.

00:55:09.086 --> 00:55:11.796 A:middle
So, what's new in ARKit 2.

00:55:11.796 --> 00:55:12.966 A:middle
Let's have a look.

00:55:13.816 --> 00:55:15.306 A:middle
We've seen saving and loading

00:55:15.306 --> 00:55:16.606 A:middle
maps, which are powerful new

00:55:16.606 --> 00:55:18.016 A:middle
features for persistence and

00:55:18.206 --> 00:55:20.436 A:middle
multiuser collaboration.

00:55:21.726 --> 00:55:23.086 A:middle
World tracking enhancements

00:55:23.506 --> 00:55:25.236 A:middle
simply shows better and fasting

00:55:25.236 --> 00:55:27.746 A:middle
plane detection as well as new

00:55:27.746 --> 00:55:29.356 A:middle
video formats.

00:55:29.566 --> 00:55:31.056 A:middle
And with environment texturing,

00:55:31.726 --> 00:55:34.256 A:middle
we can make the content really

00:55:34.506 --> 00:55:35.876 A:middle
look as if it was really in the

00:55:35.976 --> 00:55:38.526 A:middle
scene by gathering texture of

00:55:38.526 --> 00:55:39.876 A:middle
the scene and applying it as a

00:55:39.906 --> 00:55:40.616 A:middle
textured object.

00:55:41.846 --> 00:55:44.136 A:middle
And with image tracking, with

00:55:44.836 --> 00:55:48.196 A:middle
image tracking, we are now able

00:55:48.196 --> 00:55:50.516 A:middle
to track 2D objects in the form

00:55:50.516 --> 00:55:50.986 A:middle
of images.

00:55:51.506 --> 00:55:53.236 A:middle
But ARKit can also detect 3D

00:55:53.236 --> 00:55:53.586 A:middle
objects.

00:55:54.576 --> 00:55:56.386 A:middle
And for face tracking, we have

00:55:56.916 --> 00:55:59.116 A:middle
gaze and tongue.

00:55:59.926 --> 00:56:01.226 A:middle
All of this is made available

