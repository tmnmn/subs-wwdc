# What’s New in ARKit 2

## Summary
ARKit 2 makes it easy to develop vivid augmented reality experiences and enable apps to interact with the real world in entirely new ways. Discover how multiple iOS devices can simultaneously view an AR scene or play multiplayer AR games. Learn about new capabilities for tracking 2D images, and see how to detect known 3D objects like sculptures, toys, and furniture.

## Info
* Graphics and Games
* WWDC 2018 - Session 602 - iOS
* https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/

## Text
 [（ARKit 2新特性
演讲602）](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=17) [早上好](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=26) [欢迎参加我们的演讲
“ARKit 2新特性”](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=29) [我叫Arsalan
我是ARKit团队的工程师](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=34) [去年 我们非常高兴能将ARKit](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=41) [作为iOS 11更新
的一部分交给你](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=47) [ARKit已部署到数亿台设备](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=51) [使iOS成为最大
且最先进的AR平台](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=56) [ARKit为你提供了强大功能集的
简单易用的接口](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=63) [我们对你们到目前为止
使用ARKit所创造的东西](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=70) [感到非常惊讶](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=73) [让我们看看App Store中的
一些例子](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=75) [Civilizations是一款AR app
它可以在你面前展示历史文物](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=80) [你可以从各个角度查看它们](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=86) [你还可以启用X射线模式
以进行更多的交互](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=88) [你可以把它们放到你的后院](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=95) [你甚至可以将它们放到现实背景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=99) [就跟几百年前它们的样子一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=101) [因此这是一个浏览历史文物的好工具](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=105) [Boulevard AR是一款AR app
它可以让你以前所未有的方式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=110) [浏览艺术作品](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=115) [你可以将它们放在地上或墙上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=118) [你可以将它们放在地上或墙上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=118) [你可以靠近它们来查看所有的细节](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=121) [这是一个讲述艺术故事的好方法](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=126) [ARKit也是一种
教育所有人的有趣方式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=136) [Free Reverse是一款
将沉浸式地貌展现到你面前的app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=140) [你可以跟随河流穿过整个地貌](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=145) [并看到群体和野生动物](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=149) [你可以看到人类活动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=152) [如何通过建筑对这些群体
和野生动物产生影响](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=154) [所以这是教育每个人](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=162) [关于环保和可持续发展的好方法](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=164) [以上就是一些这样的例子](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=170) [你可以在App Store中
查看更多示例](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=172) [你们中有些人可能刚接触ARKit](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=177) [你们中有些人可能刚接触ARKit](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=177) [所以让我简单概述一下
ARKit是什么](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=180) [跟踪是ARKit的核心组件](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=188) [它为你提供设备在真实世界中的
位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=191) [它还可以跟踪对象
例如人脸](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=198) [场景理解](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=206) [通过获取有关环境的更多属性
来强化跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=208) [我们可以检测水平面
例如地平面或桌面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=213) [我们还可以检测垂直平面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=219) [这让你可以将虚拟对象放置在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=221) [场景理解还可以
了解环境中的光照条件](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=231) [因此你可以使用光照在虚拟场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=237) [因此你可以使用光照在虚拟场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=237) [准确反映真实环境](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=242) [从而使你的物体看起来
不会太亮或太暗](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=244) [渲染是用户实际在设备上看到的内容](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=250) [并与增强现实场景进行交互的过程](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=253) [ARKit API让你能够轻松](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=256) [集成你选择的任何渲染引擎](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=259) [ARKit为SceneKit
和SpriteKit提供内置视图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=266) [在Xcode中
我们还有一个Metal模板](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=272) [来让你快速开始自己的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=275) [注意 Unity和Unreal
将ARKit的完整功能集](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=281) [集成到它们热门的游戏引擎中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=287) [因此你可以通过使用
所有这些渲染技术](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=289) [来开始使用ARKit](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=292) [让我们看看
今年ARKit 2新特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=298) [让我们看看
今年ARKit 2新特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=298) [我们现在可以保存和加载映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=307) [它支持着持久性和多用户体验的
强大新功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=310) [我们也为你提供环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=319) [以便你可以逼真地渲染增强现实场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=322) [ARKit现在可以
实时跟踪2D图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=327) [我们不仅限于2D
我们还可以检测场景中的3D对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=333) [最后 我们为面部跟踪提供了一些
有趣的增强](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=341) [让我们从保存和加载映射开始吧](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=348) [保存和加载映射是世界跟踪的一部分](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=356) [世界跟踪可为你提供现实世界中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=360) [设备的六自由度位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=364) [这可以让你在场景中放置对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=368) [比如你在此视频中看到的这些桌椅](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=372) [世界跟踪还可以为你提供
准确的物理比例](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=378) [以便你可以正确的比例放置对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=382) [因此你的对象看起来不会太大或太小](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=386) [这也可用于实现精确测量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=394) [如昨天看到的
Measure app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=399) [世界跟踪还为你提供3D特征点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=404) [以便你了解环境的一些物理结构](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=409) [这可用于在场景中放置对象时
进行碰撞测试](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=412) [在iOS 11.3中
我们引入了重定位](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=420) [此功能可让你在AR会话中断后](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=424) [恢复跟踪状态](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=428) [这种情况可能发生在
比如你的app被切换到后台时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=432) [或者你在iPad的图片模式上
使用图片时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=436) [重定位可以与
由世界跟踪持续构建的映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=444) [一起使用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=450) [我们越是绕着环境进行移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=453) [它就越能够扩展并学习越多](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=458) [关于环境的不同特征](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=460) [该映射过去只有在你的AR会话
仍存活时才可用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=468) [但现在我们为你提供此映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=474) [ARKit API中 此映射作为
ARWorldMap对象提供给你](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=480) [ARWorldMap
代表物理3D空间的映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=494) [类似于我们在右侧视图中看到的那样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=498) [我们也知道锚是物理空间中的重要点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=505) [它们是你想要放置虚拟对象的位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=510) [我们在ARWorldMap中
默认也包含平面锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=514) [此外你还可以将自定义锚
添加到此列表中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=520) [因为这是一个可变列表](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=525) [你可以在场景中创建自定义锚
并将其添加到WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=527) [对可视化和调试 WorldMap
还为你提供原始特征点和范围](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=537) [对可视化和调试 WorldMap
还为你提供原始特征点和范围](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=537) [以便你了解刚扫描的真实物理空间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=543) [更重要的是 WorldMap
是一个可序列化对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=552) [因此它可以序列化为
你选择的任何数据流](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=557) [例如本地文件系统上的文件
或共享网络位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=561) [这个ARWorldMap对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=569) [支持着ARKit中的
两组强大的新体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=572) [首先是持久性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=579) [这是向你展示它是如何工作的
一个例子](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=584) [我们有一个用户开始进行世界跟踪
他通过ARKit碰撞测试](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=588) [将一个对象放在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=594) [在离开场景之前
他在设备上保存了WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=597) [在离开场景之前
他在设备上保存了WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=597) [过了一段时间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=608) [该用户回来了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=612) [他可以加载相同的WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=615) [并找回相同的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=618) [他可以多次重复这种体验
并且他会发现](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=622) [每次开始体验时
这些物体都会出现在桌子上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=627) [这就是世界跟踪的持久性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=631) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=637) [ARWorldMap
还支持多用户体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=644) [现在你的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=649) [不仅限于单个设备或单个用户](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=651) [它可以与许多用户共享](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=654) [一个用户可以创建WorldMap
并将其分享给一个或多个用户](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=660) [请注意 WorldMap代表
现实世界中的单个坐标系](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=668) [这意味着所有用户将共享
同一个坐标空间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=674) [他们能够从不同的角度体验到](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=680) [相同的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=683) [这是一个很棒的特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=687) [你可以使用WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=689) [实现多用户游戏
比如我们昨天看到的游戏](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=692) [我们还可使用ARWorldMap
创建多用户共享教育体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=699) [注意我们现将ARWorldMap
对象交到你手中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=710) [因此你可以自由选择
任何与其它用户共享的技术](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=715) [因此你可以自由选择
任何与其它用户共享的技术](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=715) [比如对于共享 你可以使用
AirDrop或Multipeer Connectivity](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=722) [它们依赖于本地蓝牙
或Wi-Fi连接](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=727) [这意味着你不需要联网](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=731) [就可以使用此功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=735) [让我们看看
ARKit API如何让你](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=742) [轻松实现获取
并加载WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=745) [在你的AR会话对象上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=751) [你可以在任何时间点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=753) [调用getCurrentWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=756) [此方法带有一个完成处理程序](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=759) [它将返回一个
ARWorldMap对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=762) [另外注意它也可能返回错误](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=768) [如果WorldMap不可用的话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=771) [因此在app代码中
处理此错误非常重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=774) [一旦你得到了ARWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=779) [一旦你得到了ARWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=779) [你可以简单地](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=782) [在世界跟踪配置中设置
initialWorldMap属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=787) [并运行你的会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=792) [注意这也可以动态更改](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=795) [因此你始终可以通过运行新配置
来重新配置AR会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=798) [一旦用ARWorldMap
启动了AR会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=805) [它将遵循与iOS 11.3中
引入的重定位](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=810) [完全相同的行为](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=812) [重定位的可靠性
对你的app体验来说非常重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=824) [因此获取好的WorldMap
非常重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=832) [注意你可以随时调用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=836) [getCurrentWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=838) [getCurrentWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=838) [从多个不同视角扫描你的物理空间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=842) [非常重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=846) [这样跟踪系统才可以真正理解](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=848) [周围环境的物理结构](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=851) [环境应该是静态的并且纹理清晰
以便我们可以提取它的更多特征](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=856) [并了解有关环境的更多信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=861) [而且在映射上有密集的特征点很重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=867) [这样它就可以可靠地重定位](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=872) [但你不必担心所有这些问题](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=877) [在ARKit中 其API通过向你提供
ARFrame上的WorldMappingStatus](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=881) [来大大简化你的工作](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=885) [WorldMappingStatus在每个
ARFrame中进行更新](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=889) [并且可以通过
WorldMappingStatus属性获取](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=894) [让我们看看这是如何工作的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=897) [当我们刚开始世界跟踪时
WorldMappingStatus为不可用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=901) [当我们开始扫描物理空间时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=905) [它会变为受限制](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=907) [我们在真实世界中移动得越多](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=910) [世界跟踪将继续扩展该映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=914) [如果我们从当前的角度
扫描了足够多的真实世界信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=919) [WorldMappingStatus将变为已映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=924) [注意如果你从已映射的物理空间移开](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=934) [WorldMappingStatus可能会
回到受限制状态](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=939) [并将开始学习更多](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=943) [关于我们所看到的新环境的信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=944) [那么如何在你的app代码中
使用WorldMappingStatus呢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=951) [假设你有一个app可以让你
与其他用户分享你的WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=956) [假设你有一个app可以让你
与其他用户分享你的WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=956) [并且你的用户界面上有一个
共享映射按钮](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=961) [当WorldMappingStatus
为不可用或受限制时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=967) [禁用此按钮是一种好实践](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=970) [当WorldMappingStatus为扩展时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=974) [你可能希望在UI上显示活动指示器](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=978) [这会鼓励你的终端用户
继续在物理世界中移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=981) [并继续扫描以扩展映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=986) [因为你需要它来进行重定位](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=990) [一旦WorldMappingStatus
完全映射后](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=996) [你就可以启用共享映射按钮
并隐藏你的活动指示器](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1000) [这将让你的用户可以分享该映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1005) [让我们来看一个
保存和加载WorldMap的演示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1013) [好的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1026) [我们可以切换到AR 1吗？](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1029) [好的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1033) [对于这个演示 我有两个app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1034) [第一个app中 我将获取
WorldMap并将其保存到本地文件](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1037) [第二个app中 我将加载
这个WorldMap来恢复](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1043) [同样的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1048) [让我们开始吧](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1051) [如你所见 WorldMappingStatus
位于右上角](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1055) [它为不可用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1059) [一旦我开始在环境中移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1061) [它就开始扩展我的WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1065) [如果我继续在该环境中移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1068) [WorldMappingStatus
将变为已映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1073) [这意味着它已经从这个角度
看到了足够多的特征](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1077) [这意味着它已经从这个角度
看到了足够多的特征](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1077) [来进行重定位](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1082) [现在是获取和序列化
WorldMap对象的好时机](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1083) [但先让我们放置一个自定义锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1090) [来让这个增强现实场景更有趣](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1094) [通过碰撞测试
我创建了一个自定义锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1097) [并将这个对象叠加上去](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1101) [这是一台旧电视](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1105) [我想你们大多数人以前可能见过它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1107) [当然 我仍然可以继续映射世界](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1113) [让我们保存该WorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1117) [当我保存WorldMap时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1121) [它还可以显示属于
此WorldMap的原始特征点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1123) [你看到的那些蓝点
它们都是WorldMap的一部分](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1127) [另外作为一个好实践](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1135) [在保存WorldMap时
我也保存了该视角的屏幕截图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1138) [在保存WorldMap时
我也保存了该视角的屏幕截图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1138) [现在我们已将WorldMap
序列化到我们的文件中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1147) [我们现在可以在另一个app中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1152) [恢复这个增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1155) [让我们试试吧](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1156) [我将从一个不同的位置启动此app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1158) [你可以看到这是我的世界原点
它定义在桌子的这一侧](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1164) [并且我的世界跟踪
现在处于重定位状态](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1169) [这是与我们在iOS 11.3中
引入的相同的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1173) [开放重定位行为](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1175) [让我把设备指向我刚才](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1178) [创建WorldMap的物理位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1184) [当我指向该空间时
它就会立即将我的世界原点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1188) [恢复到原来的位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1194) [同时它还恢复了我的自定义锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1196) [同时它还恢复了我的自定义锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1196) [因此我得到了完全相同的AR体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1200) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1209) [请注意我可以多次启动此app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1211) [并且每次启动时它都会
向我展示相同的体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1215) [这就是持久性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1219) [当然 这也可以与其它设备共享](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1222) [回到幻灯片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1227) [以上就是保存和加载映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1234) [这是ARKit 2中强大的新功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1237) [即支持持久性和多用户共享体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1240) [在ARKit 2中 我们有更快的
初始化和平面检测](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1249) [世界跟踪现在更加鲁棒](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1256) [我们可以在更复杂的环境中检测平面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1259) [我们可以在更复杂的环境中检测平面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1259) [水平和垂直平面
都有更准确的范围和边界](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1267) [这意味着你可以准确地将对象
放置在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1272) [在iOS 11.3中
我们为你的增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1280) [引入了连续自动对焦功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1284) [iOS 12专门针对增强现实体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1288) [进行了更多优化](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1292) [我们还在ARKit中引入了
4:3视频格式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1299) [4:3是一种广角视频格式
它极大增强了iPad上可视化效果](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1307) [因为iPad也有4:3的
显示屏宽高比](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1313) [请注意4:3视频格式将是
ARKit 2中的默认视频格式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1319) [请注意4:3视频格式将是
ARKit 2中的默认视频格式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1319) [所有这些增强特性都将应用于
App Store中所有现有app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1326) [但4:3视频格式除外](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1331) [为此你必须使用新的SDK
来重新构建你的app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1335) [回到改善终端用户体验的话题](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1343) [我们引入了环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1350) [这极大增强了终端用户的渲染体验](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1353) [假设你的设计师很努力地](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1361) [为你的增强现实场景
创建了这些虚拟对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1365) [这看起来真的很棒](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1370) [但你需要为增强现实场景做更多事情](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1372) [你需要在AR场景中保持
正确的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1379) [你需要在AR场景中保持
正确的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1379) [这样对象看起来就像是
放在真实世界中一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1386) [保证比例正确也很重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1393) [这样你的对象才不会太大或太小](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1396) [ARKit会在世界跟踪中
通过为你提供正确的转换来帮助你](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1399) [对于逼真的渲染](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1408) [考虑环境中的光照也很重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1410) [ARKit为你提供了环境光估计器
你可以在渲染时使用它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1417) [来纠正虚拟对象的亮度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1421) [以便你的物体看起来不会太亮或太暗](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1425) [它们会直接融入环境中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1429) [如果要将物体放在物理表面上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1434) [如水平面上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1438) [为对象添加阴影也很重要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1440) [这极大改善了人类的视觉感知](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1444) [他们会真正感知到物体就在表面上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1447) [最后 如果是反光物体](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1453) [人们希望](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1458) [从虚拟对象的表面看到环境的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1461) [这就是环境纹理所能达到的效果](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1465) [让我们看看这个对象
在增强现实场景中的样子](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1471) [昨天晚上在我准备这个演讲时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1478) [我创造了这个场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1480) [在吃这些水果的同时
我也想放置这个虚拟对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1484) [你可以看到比例是正确的
更重要的是](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1491) [你可以在对象中看到环境的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1498) [你可以在对象中看到环境的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1498) [在此对象的右侧](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1502) [你可以在右边看到这些水果的
黄色和橙色的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1505) [而在左侧你可以注意到
树叶的绿色纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1510) [你也可以在中间看到长凳表面的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1516) [这是通过ARKit 2中的
环境纹理实现的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1521) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1529) [环境纹理会收集场景的纹理信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1534) [通常它表示为立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1540) [但也有其它表示形式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1543) [环境纹理或这个立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1549) [可用作渲染引擎中的反射探头](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1552) [该反射探头可以将其应用为
虚拟对象上的纹理信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1558) [该反射探头可以将其应用为
虚拟对象上的纹理信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1558) [例如我们在上一张幻灯片中
看到的对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1563) [因此它极大改善了
反射物体的视觉效果](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1567) [让我们看看这个视频短片中
这是如何工作的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1575) [ARKit在运行世界跟踪
和场景理解的同时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1582) [继续了解有关环境的更多信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1586) [通过使用计算机视觉技术](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1590) [它可以提取纹理信息
并开始填充此立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1592) [而该立方体贴图被准确放置在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1599) [注意此立方体贴图只是部分填充](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1604) [为了设置反射探头](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1609) [我们需要一个完全立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1611) [要获得完全立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1617) [你需要扫描整个物理空间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1619) [你需要扫描整个物理空间](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1619) [就像使用全景装置
进行360度扫描一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1623) [但这对终端用户来说并不现实](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1628) [ARKit通过使用先进的
机器学习算法自动完成此立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1633) [来让该过程变得更简单](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1639) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1646) [另外注意所有这些处理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1651) [都实时发生在你的本地设备上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1654) [一旦我们有了立方体贴图
我们就可以设置反射探头](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1660) [并且只要我们在场景中放置虚拟对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1663) [它们就会开始反射真实环境](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1667) [这是对环境纹理化过程](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1671) [工作原理的快速概述](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1672) [让我们看看ARKit API
如何让你轻松使用此特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1677) [让我们看看ARKit API
如何让你轻松使用此特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1677) [你需要在世界跟踪配置中
做的所有事情](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1687) [就是将environmentTexturing属性
设置为.automatic并运行会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1692) [就这么简单](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1699) [AR会话将在后台自动运行
该环境纹理化过程](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1709) [并将环境纹理作为环境探头锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1713) [提供给你](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1717) [AREnvironmentProbeAnchor
是ARAnchor的扩展](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1721) [这意味着它具有六自由度的
位置和方向变换](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1725) [此外 它有个MTLTexture
形式的立方体贴图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1730) [ARKit还为你提供了
立方体贴图的物理范围](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1738) [ARKit还为你提供了
立方体贴图的物理范围](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1738) [它是反射探头所影响的区域](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1742) [并且渲染代理可以使用它来校正并行](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1747) [因此如果你的对象在场景中移动
它将自动适应到新位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1752) [并且环境中的新纹理将被反射出来](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1757) [请注意这与其它锚的生命周期相同](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1764) [例如ARPlaneAnchor
或ARImageAnchor](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1768) [此外 它被完全集成到
ARSCNView中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1776) [因此如果你使用SceneKit
作为你的渲染技术](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1780) [你只需在世界跟踪配置中启用此功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1785) [其余部分将由
ARSCNView自动完成](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1790) [注意对于高级用例
你可能想要在场景中手动放置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1800) [环境探测锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1804) [为此你需要将environmentTexturing模式
设置为.manual](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1811) [然后你就可以在你想要的位置和方向
创建环境探测锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1816) [并将它们添加到AR会话对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1821) [注意这只允许你将探测锚
放置在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1828) [AR会话一旦获得
有关环境的更多信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1833) [它就会自动更新其纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1837) [因此当你的增强现实场景
只有一个对象时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1842) [就可以使用此模式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1848) [你不希望使用太多环境探头锚
来使系统负载过高](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1849) [让我们看一个环境纹理的快速演示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1857) [让我们看一个环境纹理的快速演示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1857) [并看看我们如何逼真地渲染
增强现实场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1860) [我们切换到AR 1](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1876) [好的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1883) [对于这个演示
我所运行的世界跟踪配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1884) [未启用环境纹理功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1889) [正如你在底部开关控制器上
看到的那样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1893) [它只使用了环境光估计](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1898) [让我们放置之前见过的那个对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1901) [你可以看到](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1907) [这看起来没问题
我的意思是 你可以在桌面上看到它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1910) [你可以看到它的阴影
它看起来是一个非常好的AR场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1914) [但它不能反射桌子的木质表面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1919) [但它不能反射桌子的木质表面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1919) [而且如果我在场景中放置一些东西](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1926) [如真实的水果](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1930) [我们在虚拟对象中看不到它的倒影](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1936) [现在让我们启用环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1941) [并看看它如何逼真地显示这种纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1944) [正如你所看到的 我一启用环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1951) [对象就开始反射桌子的木质表面](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1954) [以及此香蕉的纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1958) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1970) [这极大改善了你的增强现实场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1972) [它看起来非常真实
好像它真的在桌面上一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1977) [它看起来非常真实
好像它真的在桌面上一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1977) [好的 回到幻灯片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1984) [这就是环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1992) [它是ARKit 2中强大的新功能
能够让你尽可能逼真地创建](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=1994) [你的增强现实场景](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2000) [现在 为了继续介绍其它新特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2005) [我想邀请Reinhard上台来](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2010) [Reinhard](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2018) [开始了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2020) [这能用吗？](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2022) [哦 好的 太好了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2023) [早上好 我叫Reinhard
我是ARKit团队的工程师](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2025) [接下来 我们将讨论图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2030) [在iOS 11.3中 我们引入了
图像检测作为世界跟踪的一部分](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2034) [图像检测会搜索场景中
已知的2D图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2039) [图像检测会搜索场景中
已知的2D图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2039) [这里的术语“检测”
意味着这些图像是静态的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2044) [因此它们应该不会移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2047) [这些图像的例子包括电影海报
或博物馆中的画](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2050) [一旦检测到图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2056) [ARKit将估算
其六自由度位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2060) [该姿态可用于触发
你的渲染场景中的内容](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2064) [正如我前面提到的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2069) [所有这些都完全集成在世界跟踪中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2071) [你所要做的只是在你的属性中
对它进行一次设置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2074) [为了加载用于图像检测的图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2078) [你可以从文件加载它们
或使用Xcode的素材目录](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2082) [它还可以为你提供图像的检测质量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2085) [图像检测现在已经很棒了
但在iOS 12中我们能做得更好](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2090) [让我们来谈谈图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2094) [图像跟踪是图像检测的一种扩展](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2097) [图像跟踪是图像检测的一种扩展](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2097) [但它的优势在于图像
不再需要是静态的并且可以移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2102) [ARKit现将以每秒60帧的速度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2107) [估算每一帧的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2111) [这可以让你准确地增强2D图像
比如杂志 棋盘游戏](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2113) [或任何具有真实图像特征的东西](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2120) [且ARKit也可同时跟踪多个图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2125) [默认情况下它只选择一个
但在某些情况下](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2130) [比如杂志的封面
你可能希望将它设置为1](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2134) [或者如果是杂志内的双页杂志](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2138) [你可以把它设置为2](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2142) [在iOS 12的ARKit 2中
我们有一个全新的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2145) [即ARImageTrackingConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2150) [它可让你进行独立的图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2153) [让我们看看如何设置它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2157) [我们首先加载一组
ReferenceImage](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2159) [我们首先加载一组
ReferenceImage](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2159) [其可以来自文件或素材目录](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2162) [加载完这组
ReferenceImage后](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2165) [我通过它指定
其detectionImages属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2168) [来将会话设为
WorldTrackingConfiguration类型](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2173) [或通过指定trackingImages属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2177) [将其设为ARImageTracking
Configuration类型](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2179) [完成配置后 我用它来运行我的会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2182) [和往常一样 一旦会话开始运行](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2188) [我会在每次更新时
获得一个ARFrame](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2191) [一旦检测到图像
这个ARFrame将包含一个](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2194) [ARImageAnchor类型
的对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2199) [这个ARImageAnchor
是一个可跟踪的对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2202) [我可以通过遵守
ARTrackable协议看到它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2205) [其中有一个
布尔值变量isTracked](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2208) [它可以通知你图像的跟踪状态](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2213) [如果对象已跟踪则为true
否则为false](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2216) [它还会通知你检测到的图像及其位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2220) [其位置和方向以4*4矩阵表示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2224) [为了获得这样的图像锚
一切都从加载图像开始](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2231) [这很好 让我们来看看
哪些图像比较适合跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2235) [这张图片可以在儿童书中找到](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2239) [事实上 它非常适合图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2244) [它有很多不同的视觉特征](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2246) [它的纹理清晰
并且有非常好的对比度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2248) [另一方面 在儿童书中也可以
找到这样的图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2252) [但这种图像并不合适](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2256) [它有很多重复的结构
一致的颜色区域](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2260) [并且一旦将其转换为灰度值
它将有一个非常窄的直方图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2264) [但你不必自己识别这些统计信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2268) [因为Xcode可为你提供帮助](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2270) [如果我将这两个图像导入Xcode](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2272) [我们可以看到海洋生物图像
没有任何警告](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2275) [这意味着它是推荐使用的
而有三个孩子阅读的那个图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2279) [这意味着它是推荐使用的
而有三个孩子阅读的那个图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2279) [显示警告图标以表示不建议使用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2282) [如果我点击此图标
我会得到关于为什么这个图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2286) [不适合用于图像跟踪的精确描述](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2290) [我可以得到的信息包括直方图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2294) [一致的颜色区域以及直方图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2296) [一旦我加载完图片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2301) [我有两种配置选择](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2303) [首先是
ARWorldTrackingConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2306) [我们来谈谈这个](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2309) [当我们使用世界跟踪
来进行图像跟踪时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2313) [图像锚在世界坐标系中表示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2315) [这意味着图像锚可选择平面锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2319) [相机和世界原点本身
都出现在同一个坐标系中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2324) [这使它们的互动非常简单直观](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2329) [而作为iOS 12中的新功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2334) [对于以前只能检测到的图像
现在可以进行跟踪了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2336) [对于以前只能检测到的图像
现在可以进行跟踪了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2336) [我们有了一个新的配置
即ARImageTrackingConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2342) [它可以执行独立的图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2345) [这意味着它独立于世界跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2348) [而不依赖运动传感器来进行跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2352) [这意味着此配置在开始识别图像之前
不会初始化](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2356) [并且可以在无法进行世界跟踪的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2360) [场景中成功识别](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2365) [如电梯或火车等移动平台](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2366) [在这种情况下 ARKit将以
每秒60帧的速度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2371) [估算每帧的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2375) [并且只需四行简单代码
就可以完成这项工作](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2379) [你需要做的是首先创建一个](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2383) [类型为ARImageTracking
Configuration的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2387) [并指定想要跟踪的一组图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2390) [在这个例子中
我指定了猫、狗和鸟的照片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2393) [我告诉配置我要跟踪的图像数量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2399) [我告诉配置我要跟踪的图像数量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2399) [在这个例子中 我将其指定为2](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2403) [在我的用例中
假设只有两个图像会互动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2406) [而不会同时出现三个](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2409) [注意如果我正在跟踪两个图像
而第三个图像进入其视图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2412) [它将不会被跟踪
但它仍会触发检测更新](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2417) [然后我使用此配置来运行我的会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2423) [正如我之前提到的
你也可以通过换掉这两行代码](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2427) [并使用世界跟踪来做到这点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2431) [图像检测和跟踪之间的唯一区别](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2435) [是跟踪图像的最大数量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2438) [如果你有一个使用图像检测的app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2440) [你可以简单地添加它并重新编译
然后你的app就可以使用跟踪了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2445) [为了向你展示这是多么容易
让我们在Xcode中做一个演示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2450) [我们可以切换到AR 2吗？
好的 对于这个演示](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2463) [我想创建一个AR相框](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2466) [为此我带了一张我家的猫的照片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2470) [让我们使用Xcode构建它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2473) [我先用Xcode
创建一个iOS app模板](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2476) [如你所见 它现在是空的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2482) [接下来我需要指定要附加的图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2486) [为此我导入了
我的猫Daisy的照片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2490) [让我们在这里打开她](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2493) [这就是我的猫](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2496) [我需要指定一个名字](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2500) [我将其命名为Daisy
即我的猫的名字](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2502) [我在这里指定了在现实世界中
该图像的物理宽度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2504) [即我的相框宽度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2509) [我也载入了一段我的猫的视频](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2512) [让我们把这一切都集中在一起](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2516) [首先我将创建一个配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2518) [首先我将创建一个配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2518) [这是一个
ARImageTrackingConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2521) [类型的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2524) [我通过使用组名Photos](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2527) [从素材目录中加载了一组跟踪图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2530) [其中只包含一张图片
即我的猫Daisy的照片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2533) [接下来](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2538) [我通过指定trackingImages属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2541) [设置好图像跟踪配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2542) [并将maximumNumberOfTrackedImages
设为1](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2546) [此时 app已经启动了AR会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2550) [并在检测到图像时为你提供其图像锚](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2553) [但让我们添加一些内容](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2556) [我将通过在资源面板中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2559) [载入视频并根据它创建一个
AVPlayer来加载它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2562) [现在让我们将它添加到真实图像之上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2569) [为此我需要检查该锚
是否是ImageAnchor类型](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2575) [并创建一个与场景中的图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2579) [并创建一个与场景中的图像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2579) [具有相同物理尺寸的
SCNPlane](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2583) [我将videoPlayer
设为该平面的纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2586) [并开始播放videoPlayer](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2589) [我通过geometry
创建一个SCNNode](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2593) [并反转它以匹配锚坐标系](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2596) [就是这样 我们运行它
并看看其效果](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2602) [一旦我将相机对准我的猫的相框](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2610) [视频将开始播放
我可以看到猫动了起来](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2614) [由于ARKit实时估计位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2624) [我可以自由移动设备
也可以移动对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2627) [我可以看到每一帧都在更新](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2631) [她跑掉了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2635) [我们的演示就到这里吧
让我们回到幻灯片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2638) [我们的演示就到这里吧
让我们回到幻灯片](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2638) [如你所见 在ARKit中
使用图像跟踪非常简单](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2648) [事实上 制作一个猫的视频
要比这困难得多](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2653) [图像跟踪非常适合
与2D对象进行交互](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2657) [但我们不仅限于平坦的2D物体](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2662) [我们接下来谈谈对象检测](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2665) [对象检测可用于检测场景中的
已知3D对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2673) [就像刚才的图像检测一样
术语“检测”意味着这个对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2679) [需要是静态的 也就是它不应该移动](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2683) [此类对象的很好的例子
可能是博物馆中的展品](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2688) [某些玩具或家居用品](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2692) [和图像检测一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2696) [首先需要使用运行ARKit
的iOS app扫描这个对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2698) [首先需要使用运行ARKit
的iOS app扫描这个对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2698) [为此我们提供了一个全功能
iOS app的完整源代码](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2703) [它允许你扫描自己的3D对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2708) [此类对象需要具有一些特性
比如它需要纹理良好](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2711) [刚性且无反射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2716) [它们的大小应该与桌面摆设大致相同](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2718) [ARKit可用于估计这些物体](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2723) [在六自由度中的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2727) [所有这些都完全集成到世界跟踪中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2731) [你需要做的只是设置一个属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2735) [就可以开始进行对象检测了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2738) [让我们来看看这是如何设置的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2740) [我从文件或Xcode素材目录中
加载一组ARReferenceImage](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2743) [我稍后再讨论参考对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2749) [加载完这些参考对象后](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2752) [我通过指定
detectionObjects属性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2754) [以用它们来设置我的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2759) [以用它们来设置我的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2759) [ARWorldTrackingConfiguration
类型的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2761) [设置好配置后 使用它运行会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2765) [就像图像检测一样 AR会话运行后](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2771) [每次更新
我都会得到一个ARFrame](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2774) [在这种情况下](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2776) [一旦在场景中检测到一个对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2778) [ARFrame中就会出现
一个ARObjectAnchor](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2781) [该AR对象
是ARAnchor的简单子类](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2788) [所以它有个transform变量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2793) [代表其六自由度位置和方向
且它通过ARReferenceObject类型的引用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2795) [来告诉我它检测到了哪些对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2800) [只需三行简单代码就可以实现这点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2806) [我创建了一个](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2812) [ARWorldTrackingConfiguration
类型的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2814) [并指定一组我想要检测的对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2816) [在这个例子中 我设想通过检测
一个古老的半身像和一个陶罐](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2820) [来构建一个简单的AR博物馆app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2825) [然后我用它来运行我的会话](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2828) [事实上 我们在办公室构建了这个
非常简单的AR博物馆app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2832) [所以让我们来看看](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2837) [一旦这个半身像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2839) [进入我的iOS app视图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2842) [我就可以得到其六自由度姿态
并可以用它来查看](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2844) [一个悬浮在雕像上方的
非常简单的信息图](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2849) [在这个例子中
我们只是添加了出生日期](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2852) [这个埃及女王的名字
即Nefertiti](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2855) [但你可以添加你的渲染引擎](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2858) [允许你使用的任何内容](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2860) [为了构建这个app
我必须先扫描对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2863) [所以我们来谈谈对象扫描](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2868) [对象扫描可以从世界中
提取累积场景信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2871) [它与平面估计关系密切](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2877) [其中我们使用累积场景信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2879) [其中我们使用累积场景信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2879) [来估计水平或垂直平面的位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2882) [在这种情况下 我们使用这类信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2886) [来收集有关3D对象的信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2889) [为了指定要查找对象的区域
我只需指定](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2895) [转换 范围和中心](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2899) [这实际上是一个对象周围的边界框](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2902) [用来定义它在场景中的位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2904) [Xcode素材目录
完全支持提取对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2909) [因此将它们导入新app非常容易](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2913) [并可以根据需要重复使用它们](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2918) [对于扫描 我们添加了一个新配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2922) [即ARObjectScanningConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2924) [但你无需实现自己的扫描app](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2928) [因为你可以使用
全功能扫描app的完整示例代码](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2932) [它被称为“扫描和检测3D对象”](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2936) [我们来看看这个app是如何工作的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2940) [我首先在感兴趣的对象周围
创建一个边界框](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2942) [在这个例子中
为Nefertiti的雕像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2946) [注意边界框不需要](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2949) [严格包围对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2951) [我们所关心的是](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2952) [最重要的特征点均在其范围内](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2953) [当我对边界框感到满意时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2959) [我可以点击扫描按钮
然后我们就可以开始扫描对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2961) [我可以看到扫描从下往上进行
并且这种表现形式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2967) [可以以空间形式表示扫描对象的程度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2970) [注意你不必从所有方向扫描对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2975) [例如 如果在博物馆中有一个
面向墙壁的雕像](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2979) [因此你无法从一个特定的视角检测它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2984) [那么你就不需要从那边扫描它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2989) [一旦你对扫描结果感到满意](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2993) [你就可以调整范围的中心](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2996) [你就可以调整范围的中心](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=2996) [它对应于对象的原点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3001) [这里唯一的要求](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3004) [是中心必须保持在对象的范围内](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3005) [最后 扫描app
可让你执行检测测试](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3010) [在这个例子中
从各个视角来看该检测都是成功的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3015) [这意味着这是一次很好的扫描](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3018) [我们在这里的建议是
也要将对象移动到不同的位置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3021) [来测试该检测](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3026) [在不同纹理和不同光照条件下
是否有效](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3029) [完成扫描后 你将得到
ARReferenceObject类型的对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3034) [我们在前面的图中见过它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3039) [此对象通常可以序列化为
.arobject文件扩展类型](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3042) [它有一个名称变量
其也会显示在你的素材目录中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3047) [以及用于扫描它的中心和范围变量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3052) [此外你还将得到执行扫描时
在该区域内](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3056) [找到的所有原始特征点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3059) [找到的所有原始特征点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3059) [这就是对象检测
请记住 在检测对象之前](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3065) [你需要扫描它们
但这有现成的完整源代码可用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3069) [你可以立即下载它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3072) [我们接下来谈谈面部跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3076) [当我们去年发布iPhone X时](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3084) [我们为ARKit添加了健壮的
人脸检测和跟踪功能](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3086) [ARKit以每秒60帧的速度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3090) [估计每一帧中脸的位置和方向](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3094) [这个姿态可以通过添加帽子
或替换面部的全部纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3097) [来增强用户的面部](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3102) [ARKit还为你提供拟合三角网格](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3107) [来构成
ARFaceGeometry对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3110) [此ARFaceGeometry
类型包含](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3114) [渲染这个面部网格所需的所有信息
其表现形式为网格所有顶点 三角形](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3118) [渲染这个面部网格所需的所有信息
其表现形式为网格所有顶点 三角形](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3118) [以及检测坐标](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3125) [人脸跟踪的主要锚类型
是ARFaceAnchor](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3128) [其中包含执行面部跟踪
所需的所有信息](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3131) [为了逼真地渲染这样的几何图形](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3136) [我们添加了定向光估计](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3140) [这里 ARKit使用你的光照
作为光探头](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3143) [并估算此ARDirectionLightEstimate
其包括光的强度](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3147) [方向以及色温](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3153) [此估计值足以让大多数app
看起来很棒](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3156) [但如果你的app有更复杂的需求](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3162) [我们还提供二次球谐系数](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3165) [来收集整个场景的光照条件](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3169) [从而让你的内容看起来甚至更棒](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3173) [ARKit还可以实时跟踪表情](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3177) [ARKit还可以实时跟踪表情](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3177) [这些表情是所谓的混合形状](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3181) [它们有50多种](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3183) [这种混合形状假定一个
介于0和1之间的值](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3188) [1意味着完全激活
0意味着没有](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3191) [例如 如果我张开嘴
则下颚打开系数值将接近1](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3194) [如果我合上嘴 则值接近0](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3198) [这对为你自己的虚拟角色创建动画
非常有用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3202) [在这个例子中 我使用了张开下颚
和眨左眼](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3206) [以及眨右眼来为这个简单的
盒子脸角色创建动画](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3209) [但它可以做得更好](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3214) [事实上 在我们制作表情符号时
我们使用了更多这样的混合形状](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3216) [你在这里所看到的移动蓝条](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3221) [被用来将我的面部表情
映射到熊猫脸上](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3223) [注意ARKit提供了为你自己的
角色制作动画所需的所有工具](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3229) [就像我们制作表情符号时一样](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3234) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3239) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3239) [让我们看看ARKit 2中
面部跟踪的新特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3244) [我们添加了凝视跟踪
它可以在六自由度中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3248) [跟踪左眼和右眼](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3252) [你会发现它们是
ARFaceAnchor成员变量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3261) [还有一lookAtPoint变量](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3264) [它对应于两个凝视方向的交叉点](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3266) [你可以使用此信息
为自己的角色制作动画](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3270) [或你的app的任何其它形式的输入](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3274) [而且不止如此](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3277) [我们增加了对舌头的支持](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3279) [它以新的混合形状出现](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3282) [如果我伸出舌头
这个混合形状将假设值为1](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3284) [否则为0](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3287) [你同样可以使用它来为自己的角色
制作动画或使用它](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3289) [作为你app的输入形式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3293) [谢谢](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3300) [看到自己一遍又一遍地伸出舌头
这是一个总结的好时机](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3303) [ARKit 2新特性
我们来看一下](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3308) [我们看到了保存和加载映射](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3313) [这是用于持久性和多用户协作的
强大新特性](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3317) [世界跟踪增强可以进行
更好更快的平面检测](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3321) [以及新的视频格式](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3326) [对于环境纹理](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3329) [我们可以通过收集场景纹理
并将其应用为纹理对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3331) [来让内容看起来好像真的在场景中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3336) [通过图像跟踪…](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3341) [通过图像跟踪 我们现在能够
以图像的形式跟踪2D对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3346) [但ARKit也可以检测3D对象](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3351) [对于脸部追踪
我们有凝视跟踪和舌头跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3354) [所有这些功能都以ARKit的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3359) [所有这些功能都以ARKit的](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3359) [构建块的形式供你使用](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3361) [在iOS 12中
ARKit具有五种不同的配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3366) [包括两个新增配置](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3369) [即ARImageTrackingConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3370) [它用于独立图像跟踪](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3372) [以及
ARObjectScanningConfiguration](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3374) [此外还有一系列补充类型](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3378) [可以用于与AR会话进行交互](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3380) [比如ARFrame
和ARCamera](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3383) [其中有两个新成员](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3386) [用于对象检测的
ARReferenceObject](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3388) [和用于持久性及多用户的
ARWorldMap](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3390) [ARAnchor代表了](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3394) [现实世界中的位置
锚类型也有两个新成员](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3396) [ARObjectAnchor
和AREnvironmentProbeAnchor](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3399) [我很期待看到你们将使用
iOS 12的ARKit中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3405) [所有这些构建块所构建的东西](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3408) [还有另一个很酷的演讲
关于如何在你的app中](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3420) [集成AR Quick Look
来让你的内容看起来更棒](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3424) [非常感谢 请享受大会的其余部分](https://developer.apple.com/videos/wwdc2018/videos/play/wwdc2018/602/?time=3428)