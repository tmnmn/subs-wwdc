WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:27:57.244 --> 00:28:00.147 align:start position:32% line:-1
CNNの欠点の１つは

00:28:00.247 --> 00:28:04.685 align:start position:34% line:-2
以前起こったことを
記憶できない点です

00:28:05.219 --> 00:28:07.755 align:start position:32% line:-1
１つの入力を取り込み

00:28:07.855 --> 00:28:13.827 align:start position:29% line:-2
画像の可能性のあるものを
単一出力として生成します

00:28:16.530 --> 00:28:19.700 align:start position:34% line:-2
一方 RNNは
記憶することができ

00:28:19.800 --> 00:28:24.037 align:start position:32% line:-2
入力と出力の
シーケンスが得意です

00:28:24.538 --> 00:28:28.976 align:start position:27% line:-2
例えば 画像の中の１つの
確率のセットを取り込みます

00:28:29.109 --> 00:28:31.111 align:start position:30% line:-1
それがCNNの出力です

00:28:31.211 --> 00:28:33.380 align:start position:30% line:-1
CNNが生成するものが

00:28:33.480 --> 00:28:37.084 align:start position:29% line:-2
画像のキャプションとなる
単語のシーケンスです

00:28:38.252 --> 00:28:44.224 align:start position:23% line:-2
文を構成する単語のシーケンスを
入力として取り込み

00:28:44.324 --> 00:28:49.029 align:start position:34% line:-2
例えばロシア語と
フィンランド語など

00:28:49.129 --> 00:28:52.933 align:start position:27% line:-2
異なる言語に翻訳された文を
出力できます

00:28:54.735 --> 00:28:59.807 align:start position:25% line:-2
多くのRNNのモデルの中でも
最も一般的なのが

00:28:59.907 --> 00:29:03.877 align:start position:11% line:-2
Long Short-Term Memory
略してLSTMでしょう

