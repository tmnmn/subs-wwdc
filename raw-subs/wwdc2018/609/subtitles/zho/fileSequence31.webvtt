WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:58.358 --> 00:31:01.328 align:middle line:-2
这样就不会丢失
数据中的任何特征

00:31:03.230 --> 00:31:05.832 align:middle line:-1
然后新的数据图像

00:31:06.133 --> 00:31:09.303 align:middle line:-2
被传递给LSTM原语
是长度为20的序列

00:31:10.404 --> 00:31:12.406 align:middle line:-1
然后运行20个LSTM迭代

00:31:12.906 --> 00:31:15.776 align:middle line:-2
于是LSTM处理的
是长度为20的序列

00:31:15.843 --> 00:31:17.077 align:middle line:-1
而不是2000

00:31:17.144 --> 00:31:20.514 align:middle line:-1
而且是更高级的数据特征表达

00:31:22.549 --> 00:31:24.685 align:middle line:-1
后面还有几个CNN原语

00:31:25.419 --> 00:31:28.355 align:middle line:-1
精细化数据特征

00:31:29.389 --> 00:31:32.893 align:middle line:-2
序列的最后一个原语
是SoftMax

00:31:33.193 --> 00:31:36.263 align:middle line:-1
分配概率值给不同的动作类别

00:31:36.330 --> 00:31:37.731 align:middle line:-1
这就是网络的输出

00:31:38.632 --> 00:31:40.901 align:middle line:-1
现在看看怎样训练它

00:31:42.202 --> 00:31:44.938 align:middle line:-1
我们还是需要一个损失原语

00:31:45.005 --> 00:31:46.507 align:middle line:-1
将网络的输出

00:31:46.573 --> 00:31:48.008 align:middle line:-1
和标签作为输入

00:31:48.542 --> 00:31:50.410 align:middle line:-1
然后是下半部分图形

00:31:51.111 --> 00:31:54.481 align:middle line:-1
在下半部分还是梯度原语

00:31:54.548 --> 00:31:56.350 align:middle line:-1
对应正向原语

00:31:56.416 --> 00:31:58.218 align:middle line:-1
包括LSTM原语

00:31:59.052 --> 00:32:00.287 align:middle line:-1
那么训练

