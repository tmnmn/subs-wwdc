WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:07:59.980 --> 00:08:01.782 align:middle line:-1
反向传播

00:08:02.549 --> 00:08:03.717 align:middle line:-1
通过网络

00:08:04.184 --> 00:08:06.086 align:middle line:-1
通过第一个…

00:08:06.987 --> 00:08:09.489 align:middle line:-1
梯度原语向后传递

00:08:09.556 --> 00:08:12.826 align:middle line:-2
这个例子中
梯度原语为SoftMax

00:08:14.027 --> 00:08:15.495 align:middle line:-1
要用到链式法则

00:08:15.562 --> 00:08:18.065 align:middle line:-1
链式法则允许反向传播梯度

00:08:18.131 --> 00:08:19.333 align:middle line:-1
通过网络向后走

00:08:20.467 --> 00:08:22.302 align:middle line:-1
同时计算梯度

00:08:22.369 --> 00:08:23.737 align:middle line:-1
以更新权重

00:08:24.271 --> 00:08:27.374 align:middle line:-1
因此权重的增量很小

00:08:27.975 --> 00:08:29.276 align:middle line:-1
在每次迭代中

00:08:31.311 --> 00:08:33.480 align:middle line:-1
然后用更新后的权重

00:08:33.547 --> 00:08:35.115 align:middle line:-1
进行下次训练迭代

00:08:35.883 --> 00:08:38.184 align:middle line:-1
希望误差值会变小

00:08:38.251 --> 00:08:39.753 align:middle line:-1
这是我们努力的方向

00:08:43.557 --> 00:08:45.692 align:middle line:0
实际上
在任何训练场景中

00:08:46.326 --> 00:08:48.462 align:middle line:0
不可能只处理一张图像

00:08:49.062 --> 00:08:52.299 align:middle line:0
而是处理
一组或一批图像

00:08:52.366 --> 00:08:55.135 align:middle line:0
比如32或64的批大小

00:08:55.869 --> 00:08:59.439 align:middle line:0
还要有相应的一批标签

00:08:59.506 --> 00:09:00.674 align:middle line:0
用于计算损失

