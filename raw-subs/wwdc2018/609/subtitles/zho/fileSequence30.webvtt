WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:29:59.132 --> 00:30:01.201 align:middle line:-1
你看到网络的

00:30:02.135 --> 00:30:03.537 align:middle line:-1
配置很有趣

00:30:03.604 --> 00:30:08.175 align:middle line:-1
它含有一系列CNN原语

00:30:08.242 --> 00:30:10.244 align:middle line:-1
随后是LSTM原语

00:30:10.310 --> 00:30:12.312 align:middle line:-1
再后面是更多的CNN原语

00:30:12.579 --> 00:30:14.648 align:middle line:-2
为什么这样设置？
我们来一窥究竟

00:30:16.984 --> 00:30:19.553 align:middle line:-1
尽管输入的是感官数据

00:30:20.487 --> 00:30:23.156 align:middle line:-1
但显示的是一批1D图像

00:30:23.223 --> 00:30:24.291 align:middle line:-1
6个特征通道

00:30:24.358 --> 00:30:28.128 align:middle line:-2
一个特征通道
用于读取加速传感器

00:30:28.195 --> 00:30:29.663 align:middle line:-1
和陀螺仪上的数据

00:30:30.631 --> 00:30:33.967 align:middle line:-1
每张1D图像为2000像素

00:30:34.034 --> 00:30:37.171 align:middle line:-1
你可以将它们当作即时样本

00:30:37.738 --> 00:30:40.474 align:middle line:-1
因为我们要识别的动作

00:30:40.541 --> 00:30:41.775 align:middle line:-1
是随时发生的

00:30:44.645 --> 00:30:48.415 align:middle line:-2
然后通过1D卷积原语
传递这些图像

00:30:49.283 --> 00:30:53.820 align:middle line:-1
它将2000个样本压缩到20个

00:30:56.123 --> 00:30:58.292 align:middle line:-1
但它要占用几个特征通道

00:30:58.358 --> 00:31:01.328 align:middle line:-2
这样就不会丢失
数据中的任何特征

