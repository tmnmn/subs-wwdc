WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:36:59.336 --> 00:37:00.736 A:middle
platform State of the Union,

00:37:01.296 --> 00:37:03.056 A:middle
training the InceptionV3

00:37:03.056 --> 00:37:05.386 A:middle
Network, in TensorFlow powered

00:37:05.386 --> 00:37:09.316 A:middle
by MPS, is up to 20 times faster

00:37:09.316 --> 00:37:10.166 A:middle
than without MPS.

00:37:10.336 --> 00:37:12.056 A:middle
So, this is it for the

00:37:12.056 --> 00:37:12.996 A:middle
TensorFlow demo.

00:37:13.536 --> 00:37:20.486 A:middle
Thank you very much.

00:37:21.836 --> 00:37:23.256 A:middle
And now, let's summarize this

00:37:23.256 --> 00:37:23.636 A:middle
session.

00:37:24.926 --> 00:37:26.596 A:middle
This year, we've added a FP16

00:37:26.686 --> 00:37:29.176 A:middle
accumulation for the convolution

00:37:29.176 --> 00:37:30.486 A:middle
and convolution transpose

00:37:30.486 --> 00:37:33.056 A:middle
primitives to improve the

00:37:33.056 --> 00:37:34.596 A:middle
performance of CNN inference.

00:37:35.246 --> 00:37:36.966 A:middle
We've also added GPU accelerate

00:37:37.106 --> 00:37:38.786 A:middle
primitives for training neural

00:37:38.786 --> 00:37:39.296 A:middle
networks.

00:37:39.536 --> 00:37:41.016 A:middle
These primitives are optimized

00:37:41.086 --> 00:37:43.036 A:middle
for both iOS and macOS.

00:37:44.806 --> 00:37:45.866 A:middle
We've also added the neural

00:37:45.866 --> 00:37:47.526 A:middle
network graph API for training.

00:37:48.476 --> 00:37:50.186 A:middle
It makes it very easy to train

00:37:50.186 --> 00:37:52.016 A:middle
neural networks on the GPU and

00:37:52.016 --> 00:37:54.346 A:middle
enables us to provide the best

00:37:54.346 --> 00:37:55.996 A:middle
performance across different

00:37:56.706 --> 00:37:56.866 A:middle
GPUs.

00:37:58.066 --> 00:38:00.046 A:middle
For more information on this

