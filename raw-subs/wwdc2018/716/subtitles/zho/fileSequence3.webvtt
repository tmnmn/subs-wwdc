WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:02:56.310 --> 00:03:00.047 align:middle line:0
如果你有兴趣了解有关
集成Vision和CoreML更多信息

00:03:00.113 --> 00:03:02.349 align:middle line:0
我邀请你参加
这个会议室的下一个演讲

00:03:02.416 --> 00:03:05.919 align:middle line:0
其中我的同事Frank
将介绍这种集成的细节

00:03:08.488 --> 00:03:10.090 align:middle line:0
让我们来看看请求处理程序

00:03:11.191 --> 00:03:12.359 align:middle line:-1
在Vision中 我们有两个

00:03:12.426 --> 00:03:16.196 align:middle line:-2
我们有图像请求处理程序
也有序列请求处理程序

00:03:16.263 --> 00:03:18.832 align:middle line:-1
让我们使用这些标准来比较它们

00:03:20.200 --> 00:03:22.069 align:middle line:0
我们首先看一下图像请求处理程序

00:03:24.037 --> 00:03:28.675 align:middle line:0
图像请求处理程序用于处理
同一图像上的一个或多个请求

00:03:30.077 --> 00:03:32.546 align:middle line:0
它没有说的是
它会缓存某些信息

00:03:32.613 --> 00:03:35.649 align:middle line:0
比如图像衍生物和上一个请求的结果

00:03:35.949 --> 00:03:39.019 align:middle line:0
从而使管道中的其它请求
可以使用这些信息

00:03:39.887 --> 00:03:41.221 align:middle line:0
我来举个例子

00:03:41.288 --> 00:03:44.024 align:middle line:0
如果请求依赖于运行神经网络

00:03:44.091 --> 00:03:47.027 align:middle line:-2
如你所知
神经网络需要具有特定尺寸

00:03:47.094 --> 00:03:48.495 align:middle line:-1
和特定色彩方案的图像

00:03:48.562 --> 00:03:53.066 align:middle line:-2
假设你的神经网络预期处理
500x500的黑白图像

00:03:53.834 --> 00:03:57.137 align:middle line:-2
你获得的用户输入很少会
直接匹配该格式

00:03:57.204 --> 00:03:59.706 align:middle line:-2
所以我们在内部做的是
我们将转换图像

00:03:59.773 --> 00:04:03.076 align:middle line:-2
我们会将其输入神经网络
以获取当前请求的结果

