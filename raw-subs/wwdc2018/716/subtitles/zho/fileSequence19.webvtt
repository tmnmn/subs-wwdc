WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:57.204 --> 00:19:00.240 align:middle line:-2
我们在上一张幻灯片中看到的字段
可能看起来像这样

00:19:00.307 --> 00:19:03.544 align:middle line:-2
你有一个唯一的数字来标识
这个特定的处理步骤

00:19:04.144 --> 00:19:05.679 align:middle line:-1
然后是边界框的位置

00:19:05.746 --> 00:19:08.715 align:middle line:-1
这是处理此请求的主要结果

00:19:09.183 --> 00:19:11.952 align:middle line:-2
而landmarks字段被设置为nil
因为面部检测器

00:19:12.019 --> 00:19:13.554 align:middle line:-1
对人脸特征点一无所知

00:19:14.755 --> 00:19:18.058 align:middle line:-2
接下来我要做的是
创建我的人脸特征点请求

00:19:18.492 --> 00:19:20.961 align:middle line:-1
然后我将使用上一步的结果

00:19:21.028 --> 00:19:24.565 align:middle line:-2
并将其传入该请求的
inputObjectObservation属性

00:19:25.933 --> 00:19:28.402 align:middle line:-1
然后 我将要求请求处理程序处理它

00:19:29.236 --> 00:19:31.004 align:middle line:-1
最后 我将查看结果

00:19:31.605 --> 00:19:33.173 align:middle line:-1
如果我在同一张图片上运行它

00:19:33.240 --> 00:19:37.778 align:middle line:-2
我得到的结果
与上一张幻灯片完全相同

00:19:38.679 --> 00:19:40.480 align:middle line:-1
但让我们看看观察有何不同

00:19:40.881 --> 00:19:43.050 align:middle line:-1
记住 我们说过观察是不可变的

00:19:43.550 --> 00:19:47.621 align:middle line:-1
尽管面部检测器和人脸特征点检测器

00:19:47.688 --> 00:19:50.691 align:middle line:-2
返回的是相同的类型
但我们不会覆盖

00:19:50.757 --> 00:19:52.659 align:middle line:-1
被传入的观察

00:19:53.193 --> 00:19:55.963 align:middle line:-1
我们所做的是将前两个字段

00:19:56.029 --> 00:19:57.631 align:middle line:-1
复制到一个新对象中

00:19:58.265 --> 00:20:00.801 align:middle line:-2
然后计算特征点
并填充landmarks字段

