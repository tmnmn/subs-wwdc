WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:32:59.826 --> 00:33:01.026 A:middle
we'll simply evaluate the layer

00:33:01.026 --> 00:33:02.546 A:middle
on the CPU with no other work on

00:33:02.546 --> 00:33:03.506 A:middle
your part.

00:33:04.256 --> 00:33:06.016 A:middle
So no matter how quickly

00:33:06.016 --> 00:33:07.186 A:middle
advancements in neural network

00:33:07.186 --> 00:33:08.466 A:middle
models may happen, you have a

00:33:08.466 --> 00:33:09.716 A:middle
way to keep up with Core ML.

00:33:10.556 --> 00:33:11.936 A:middle
But there are limitations.

00:33:12.836 --> 00:33:14.196 A:middle
Custom layers only work for

00:33:14.196 --> 00:33:15.476 A:middle
neural network models, and they

00:33:15.476 --> 00:33:16.816 A:middle
only take inputs and outputs

00:33:16.816 --> 00:33:18.066 A:middle
which are ML MultiArrays.

00:33:18.066 --> 00:33:19.986 A:middle
This is a natural way to

00:33:19.986 --> 00:33:21.326 A:middle
interact with neural networks.

00:33:21.686 --> 00:33:22.706 A:middle
But the machine learning field

00:33:22.706 --> 00:33:24.406 A:middle
is hardly restricted to only

00:33:24.406 --> 00:33:25.556 A:middle
advancing in this area.

00:33:26.656 --> 00:33:27.666 A:middle
In fact, when I was first

00:33:27.666 --> 00:33:28.406 A:middle
learning about image

00:33:28.406 --> 00:33:29.996 A:middle
recognition, almost no one was

00:33:29.996 --> 00:33:31.416 A:middle
talking about neural networks as

00:33:31.416 --> 00:33:32.626 A:middle
a solution to that problem.

00:33:32.986 --> 00:33:34.006 A:middle
And you can see today it's the

00:33:34.006 --> 00:33:37.186 A:middle
absolute state of the art.

00:33:37.186 --> 00:33:38.686 A:middle
And it's not hard to imagine

00:33:38.686 --> 00:33:39.896 A:middle
machine-learning-enabled app

00:33:39.896 --> 00:33:41.426 A:middle
experiences where custom layers

00:33:41.426 --> 00:33:42.426 A:middle
simply wouldn't fit.

00:33:42.906 --> 00:33:44.666 A:middle
For instance, a machine-learning

00:33:44.666 --> 00:33:46.246 A:middle
app might use a neural network

00:33:46.246 --> 00:33:47.446 A:middle
to embed an image in some

00:33:47.446 --> 00:33:49.356 A:middle
similarity space, then look up

00:33:49.356 --> 00:33:50.576 A:middle
similar images using a

00:33:50.576 --> 00:33:51.776 A:middle
nearest-neighbor method or

00:33:51.776 --> 00:33:53.456 A:middle
locality-sensitive hashing -- or

00:33:53.456 --> 00:33:54.626 A:middle
even some other approach.

00:33:56.896 --> 00:33:58.306 A:middle
A model might combine audio and

00:33:58.306 --> 00:33:59.736 A:middle
motion data to provide a bit of

00:33:59.736 --> 00:34:01.096 A:middle
needed encouragement to someone

