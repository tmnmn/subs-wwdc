WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:00.040 --> 00:24:03.911 align:middle line:-2
它需要一个输入的图像
并简单地返回风格化的图像

00:24:04.344 --> 00:24:07.047 align:middle line:-1
有两个关键组件可以实现这一点

00:24:07.414 --> 00:24:11.618 align:middle line:-2
第一个是MLModel文件
它存储了

00:24:11.685 --> 00:24:13.053 align:middle line:-1
应用此风格所需的特定参数

00:24:13.453 --> 00:24:15.656 align:middle line:-1
第二个是推理引擎

00:24:15.722 --> 00:24:18.058 align:middle line:-1
它摄入MLModel和图像

00:24:18.125 --> 00:24:21.061 align:middle line:-1
并执行必要的计算以生成结果

00:24:21.862 --> 00:24:24.464 align:middle line:-1
让我们来看看这个推理引擎的底层

00:24:24.531 --> 00:24:28.502 align:middle line:-2
以及我们如何利用Apple
提供的技术高效地执行这种风格转换

00:24:30.170 --> 00:24:32.439 align:middle line:-1
这个模型是一个神经网络的例子

00:24:32.506 --> 00:24:35.976 align:middle line:-1
它由一系列称为层的数学运算组成

00:24:36.376 --> 00:24:39.179 align:middle line:-1
每个层都会对图像进行一些转换

00:24:39.246 --> 00:24:41.748 align:middle line:-1
最终产生风格化输出

00:24:42.616 --> 00:24:45.352 align:middle line:-1
模型存储了每个层的权重

00:24:45.419 --> 00:24:48.622 align:middle line:-2
这些权重决定了特定的转换
以及我们将要应用的风格

00:24:49.523 --> 00:24:51.558 align:middle line:-1
Core ML神经网络推理引擎

00:24:51.625 --> 00:24:54.862 align:middle line:-2
为这些层中的每一层
都进行了高度优化的实现

00:24:55.128 --> 00:24:57.364 align:middle line:-1
在GPU上 我们使用MTL着色器

00:24:57.431 --> 00:25:00.767 align:middle line:-2
在CPU上 我们可以使用
Accelerate进行有效计算

