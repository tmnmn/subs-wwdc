WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:57.384 --> 00:02:01.455 align:middle line:-2
及其带来的体验
而不是那些实现细节

00:02:04.758 --> 00:02:06.894 align:middle line:0
将Core ML模型添加到
你的app中 非常简单

00:02:06.960 --> 00:02:09.896 align:middle line:0
只需将该文件添加到
你的Xcode项目即可

00:02:11.131 --> 00:02:14.968 align:middle line:0
Xcode会显示一个简单的视图

00:02:15.035 --> 00:02:18.939 align:middle line:0
根据其输入及输出来描述它的功能

00:02:20.073 --> 00:02:23.544 align:middle line:0
Xcode还能更进一步
为你生成一个接口

00:02:24.811 --> 00:02:27.748 align:middle line:-2
这样只需几行代码就可以
与这个模型交互

00:02:28.782 --> 00:02:30.250 align:middle line:-1
一行用来加载模型

00:02:31.318 --> 00:02:32.586 align:middle line:-1
一行进行预测

00:02:33.687 --> 00:02:36.857 align:middle line:-2
有时可以再加一行代码
来提取你感兴趣的特定输出

00:02:37.991 --> 00:02:40.694 align:middle line:-2
注意在某些情况下
你甚至不必编写这些代码

00:02:40.761 --> 00:02:43.764 align:middle line:-2
因为Core ML与我们的一些
更高级的API集成在一起

00:02:43.830 --> 00:02:47.434 align:middle line:-2
若你为它们提供Core ML模型
它会允许你自定义它们的行为

00:02:48.101 --> 00:02:51.839 align:middle line:-2
在Vision中 这通过
VNCoreMLRequest对象完成的

00:02:51.905 --> 00:02:53.574 align:middle line:-1
新Natural Language框架中

00:02:53.640 --> 00:02:56.677 align:middle line:-2
你可以从Core ML模型中
实例化一个MLModel

00:02:59.513 --> 00:03:01.014 align:middle line:-1
这即Core ML的简介

