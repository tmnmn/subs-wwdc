WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:56.830 --> 00:10:00.267 align:middle line:-1
但还不止如此 我们可以走得更远

00:10:00.767 --> 00:10:04.171 align:middle line:-1
比如我们可以限制网络

00:10:04.238 --> 00:10:08.141 align:middle line:-1
只能取8种值 而不是256种

00:10:09.610 --> 00:10:11.845 align:middle line:-1
既然现在我们只有8种可能

00:10:12.513 --> 00:10:16.350 align:middle line:-2
Core ML中每个权重将需要
用3位值来存储你的模型

00:10:17.518 --> 00:10:18.919 align:middle line:-1
这里有一些细节

00:10:19.353 --> 00:10:21.154 align:middle line:-1
关于我们如何选择这些值

00:10:21.221 --> 00:10:22.489 align:middle line:-1
来表示其权重

00:10:22.756 --> 00:10:26.026 align:middle line:0
它们可以在取值范围内均匀分布

00:10:26.093 --> 00:10:28.295 align:middle line:0
在这种情况下 它是一个线性量化

00:10:29.296 --> 00:10:31.431 align:middle line:0
然而如果是查找表量化

00:10:33.333 --> 00:10:37.204 align:middle line:0
我们可以任意的方式
将这些可能取值分散在这个范围内

00:10:37.738 --> 00:10:42.009 align:middle line:0
现在我们来看看
量化如何帮助我们减小模型的大小

00:10:42.342 --> 00:10:44.912 align:middle line:-2
在这个例子中
我们关注的是Resnet50

00:10:45.212 --> 00:10:47.748 align:middle line:-2
这是许多app用来
执行许多不同的任务的

00:10:47.814 --> 00:10:49.016 align:middle line:-1
常见体系结构

00:10:49.983 --> 00:10:52.853 align:middle line:-1
它包含2500万个训练参数

00:10:53.587 --> 00:10:56.990 align:middle line:-2
这意味着如果你使用
32位浮点数来表示它

00:10:57.925 --> 00:11:00.694 align:middle line:-1
那么总模型大小超过100兆字节

