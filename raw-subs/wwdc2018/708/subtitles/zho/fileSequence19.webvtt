WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:56.036 --> 00:19:01.341 align:middle line:-2
但在某些情况下
有可能使用同一个模型

00:19:01.408 --> 00:19:03.744 align:middle line:-1
来支持两种不同的功能

00:19:04.378 --> 00:19:07.080 align:middle line:-1
例如 你可以训练一个多任务模型

00:19:07.514 --> 00:19:11.685 align:middle line:-2
多任务模型被训练成
一次执行多项任务

00:19:12.352 --> 00:19:14.121 align:middle line:-2
Turi Create演讲中
有个关于风格转换的例子

00:19:14.188 --> 00:19:16.356 align:middle line:-1
涉及到多任务模型

00:19:16.823 --> 00:19:18.325 align:middle line:-1
或者 在某些情况下

00:19:18.692 --> 00:19:21.061 align:middle line:-1
你可以在Core ML中使用一个

00:19:21.128 --> 00:19:23.063 align:middle line:-1
被称为“弹性形状和尺寸”的新特性

00:19:24.298 --> 00:19:27.801 align:middle line:0
让我们回到风格转换演示

00:19:28.135 --> 00:19:32.339 align:middle line:0
在Xcode中
我们看到输入图像和输出图像的大小

00:19:32.840 --> 00:19:36.076 align:middle line:0
被编码到模型的部分定义中

00:19:36.777 --> 00:19:40.414 align:middle line:0
但如果我们想在不同的图像分辨率下
运行相同的风格呢？

00:19:41.014 --> 00:19:45.385 align:middle line:0
如果我们想在不同的图像尺寸上
运行相同的网络 该怎么办？

00:19:46.787 --> 00:19:47.821 align:middle line:-1
例如

00:19:48.121 --> 00:19:51.258 align:middle line:-2
用户可能希望看到
高清版本的风格转换

00:19:51.792 --> 00:19:55.095 align:middle line:-1
所以他们给我们一个高清图像

00:19:55.596 --> 00:19:59.233 align:middle line:-2
现在如果我们的Core ML模型
仅以较低的分辨率作为输入

