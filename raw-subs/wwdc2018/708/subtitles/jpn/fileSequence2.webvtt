WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:01:57.384 --> 00:02:01.755 align:start position:34% line:-2
実現している体験に
注目してください

00:02:04.791 --> 00:02:10.030 align:start position:21% line:-2
Core MLモデルの追加は
Xcodeのプロジェクトにファイルを加えるだけ

00:02:11.198 --> 00:02:13.066 align:start position:34% line:-2
シンプルなビューが
出てきます

00:02:13.667 --> 00:02:17.204 align:start position:27% line:-2
実現したい動作の設定のため
必要な入力と―

00:02:17.304 --> 00:02:19.173 align:start position:27% line:-1
提供される出力を指定します

00:02:20.107 --> 00:02:23.844 align:start position:25% line:-2
次に進むとインターフェイスが
表示されます

00:02:24.811 --> 00:02:27.915 align:start position:30% line:-2
数行のコードで
このモデルが使えます

00:02:28.815 --> 00:02:32.853 align:start position:23% line:-2
１行目ではモデルのロード
２行目では推論を指示しています

00:02:33.687 --> 00:02:36.890 align:start position:27% line:-2
３行目にあるように
特定の出力を指定することもできます

00:02:38.091 --> 00:02:40.694 align:start position:30% line:-2
コードの書き直しが
不要なことも

00:02:40.794 --> 00:02:43.764 align:start position:23% line:-2
Core MLが高度なAPIに
統合されているからです

00:02:43.864 --> 00:02:47.668 align:start position:25% line:-2
Core MLモデルの提供だけで
カスタマイズも可能です

00:02:48.068 --> 00:02:51.872 align:start position:14% line:-2
Visionでは
VNCoreMLRequestで行います

00:02:51.972 --> 00:02:53.507 align:start position:12% line:-1
新しいNatural Languageでは

00:02:53.607 --> 00:02:56.944 align:start position:14% line:-2
Core MLモデルからNLModelの
インスタンスが生成できます

00:02:59.513 --> 00:03:01.114 align:start position:23% line:-1
以上がCore MLの概要です

