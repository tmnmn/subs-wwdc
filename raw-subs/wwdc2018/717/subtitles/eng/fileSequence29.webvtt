WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:28:59.746 --> 00:29:02.726 A:middle
All I have to do is use my Core

00:29:02.726 --> 00:29:04.376 A:middle
ML model, just as I did in the

00:29:04.466 --> 00:29:06.596 A:middle
previous example, create my Core

00:29:06.596 --> 00:29:09.276 A:middle
ML request, and afterwards, I'm

00:29:09.356 --> 00:29:10.906 A:middle
looking actually at simply, "How

00:29:10.906 --> 00:29:12.026 A:middle
do I draw my results?"

00:29:13.066 --> 00:29:17.856 A:middle
Now this is where we have

00:29:17.856 --> 00:29:20.076 A:middle
something new to make this

00:29:20.076 --> 00:29:21.096 A:middle
[inaudible] a little bit easier.

00:29:21.876 --> 00:29:24.066 A:middle
And when we look at all of this,

00:29:24.776 --> 00:29:27.066 A:middle
we get a new object that is the

00:29:27.066 --> 00:29:28.106 A:middle
[inaudible] recognized --

00:29:28.816 --> 00:29:30.886 A:middle
Recognized Object Observation,

00:29:31.626 --> 00:29:33.256 A:middle
and out of that, I get my

00:29:33.256 --> 00:29:35.786 A:middle
bounding box, and my observation

00:29:35.786 --> 00:29:36.766 A:middle
of like the labels.

00:29:38.006 --> 00:29:38.826 A:middle
Now, that's one thing I would

00:29:38.826 --> 00:29:39.736 A:middle
like to show you here.

00:29:40.936 --> 00:29:42.276 A:middle
Let's run our application from

00:29:42.276 --> 00:29:43.506 A:middle
here and I put a break point.

00:29:51.066 --> 00:29:51.796 A:middle
Okay.

00:29:52.726 --> 00:29:55.206 A:middle
Alright, we are now on our break

00:29:55.206 --> 00:29:55.476 A:middle
point.

00:29:56.276 --> 00:29:57.956 A:middle
So that I only look at the first

00:29:57.956 --> 00:29:58.226 A:middle
label.

00:29:58.226 --> 00:29:59.886 A:middle
So, what we are doing when we

00:29:59.886 --> 00:30:01.456 A:middle
actually process these results,

