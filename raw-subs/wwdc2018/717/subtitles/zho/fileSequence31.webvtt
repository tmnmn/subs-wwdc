WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:30:58.458 --> 00:31:00.360 align:middle line:-1
我们通过使用一个新的API

00:31:00.661 --> 00:31:05.165 align:middle line:-2
即我们的VNRecognized
ObjectObservation来使这成为可能

00:31:07.234 --> 00:31:11.471 align:middle line:-2
当我们执行
CoreMLModelRequest

00:31:11.538 --> 00:31:17.144 align:middle line:-2
且若该模型实际上基于对象检测器时
我们就会自动得到它

00:31:20.848 --> 00:31:23.851 align:middle line:-2
如该示例一样
它是基于YOLO的模型

00:31:23.917 --> 00:31:27.154 align:middle line:-2
现在你可能会说
“我也可以像去年那样运行YOLO

00:31:27.221 --> 00:31:29.022 align:middle line:-1
我在网上看到了很多相关文章”

00:31:29.756 --> 00:31:32.626 align:middle line:-1
但是看看他们实际需要编写多少代码

00:31:32.693 --> 00:31:34.561 align:middle line:-1
才能获取此模型的输出

00:31:34.628 --> 00:31:36.530 align:middle line:-1
并将它放入你可以使用的东西中

00:31:36.663 --> 00:31:38.899 align:middle line:-1
而我们在这里只用了几行代码

00:31:38.966 --> 00:31:41.401 align:middle line:-2
因此它使YOLO模型变得
非常容易使用

00:31:42.102 --> 00:31:43.837 align:middle line:-1
我们再来看一次这些代码

00:31:44.238 --> 00:31:48.208 align:middle line:-2
我创建了我的模型
根据该模型创建了我的请求

00:31:48.909 --> 00:31:52.913 align:middle line:-2
在我的完成处理程序中
我可以简单地看一下对象的区域

00:31:52.980 --> 00:31:55.449 align:middle line:-2
因为我们看到
我们可以得到多个对象

00:31:55.916 --> 00:31:58.385 align:middle line:-1
我从中获取标签和边界框

00:31:58.452 --> 00:32:00.387 align:middle line:-1
然后就可以将其显示到早餐查找器中

