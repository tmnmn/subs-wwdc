WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:24:58.532 --> 00:25:02.803 align:middle line:-2
运行在后台队列上 以便你的UI
或你在相机中做的任何事情

00:25:02.870 --> 00:25:04.471 align:middle line:-1
可以继续运行而不会卡死

00:25:04.972 --> 00:25:06.840 align:middle line:-1
但在做这点时 特别是对于相机

00:25:06.907 --> 00:25:10.143 align:middle line:-2
你不想持续将来自相机的缓冲区
放入队列

00:25:10.210 --> 00:25:14.381 align:middle line:-2
所以你应该放弃繁忙的缓冲区
在这个例子中 我说过我只用了一个

00:25:14.448 --> 00:25:16.950 align:middle line:-2
这实际上在我的用例场景中
效果非常好

00:25:17.184 --> 00:25:20.621 align:middle line:-2
我用的是大小为1的队列
这就是为什么我只检查一个缓冲区

00:25:20.687 --> 00:25:23.624 align:middle line:-2
只要它正在运行
我就不会将新的缓冲区放入队列

00:25:23.891 --> 00:25:28.161 align:middle line:-2
当其处理完成后
我就可以重置并处理下一个缓冲区

00:25:31.131 --> 00:25:32.399 align:middle line:-1
现在你可能会问

00:25:32.699 --> 00:25:35.569 align:middle line:-2
当我能在Core ML中运行
该模型时 为何要用Vision？

00:25:35.636 --> 00:25:36.770 align:middle line:-1
这毕竟是Core ML模型啊

00:25:38.138 --> 00:25:41.842 align:middle line:-2
以下是使用Vision的
一个重要原因

00:25:42.242 --> 00:25:45.279 align:middle line:-1
让我们回过头看看我们的模型

00:25:45.579 --> 00:25:49.149 align:middle line:-1
这是奇怪的299x299像素参数

00:25:49.550 --> 00:25:51.518 align:middle line:-1
这就是这个模型的训练方式

00:25:51.585 --> 00:25:53.253 align:middle line:-1
这就是它想要作为输入的内容

00:25:53.787 --> 00:25:56.790 align:middle line:-2
但是相机给我们的是
640x480的照片

00:25:56.857 --> 00:25:58.825 align:middle line:-2
或更高的分辨率
如果你愿意的话

00:25:59.793 --> 00:26:03.964 align:middle line:-2
而Vision将完成所有这些工作
它获取这些来自相机的YUV缓冲区

