WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:00.013 --> 00:03:03.217 align:middle line:-1
增强将帮助你使此模型更加强大

00:03:04.017 --> 00:03:05.919 align:middle line:-1
但它并没有取代多样性

00:03:05.986 --> 00:03:10.691 align:middle line:-2
所以你仍然希望拥有许多
想要分类的对象图像

00:03:11.258 --> 00:03:13.694 align:middle line:0
但通过增强 我们要做的是

00:03:13.760 --> 00:03:15.596 align:middle line:0
我们拍摄一张照片并扰乱它

00:03:15.996 --> 00:03:19.399 align:middle line:0
我们对其添加噪声 模糊它
旋转它 翻转它

00:03:19.466 --> 00:03:22.503 align:middle line:0
所以当我们训练它时
它在分类器看来有所不同

00:03:24.738 --> 00:03:27.474 align:middle line:-1
我们来看一下训练的实际运作方式

00:03:29.343 --> 00:03:32.346 align:middle line:-2
你可能已经听过
“迁移学习”这个术语

00:03:32.412 --> 00:03:35.616 align:middle line:-2
这正是当我们训练分类器时
在Create ML中使用的方法

00:03:36.283 --> 00:03:38.385 align:middle line:-1
我们从一个预训练模型开始

00:03:38.452 --> 00:03:40.554 align:middle line:-1
这是所有繁重过程发生的地方

00:03:40.621 --> 00:03:44.958 align:middle line:-2
这些模型通常训练数周
并且有数百万张图像

00:03:45.158 --> 00:03:48.562 align:middle line:-1
这是你需要实际使用它的第一个起点

00:03:50.364 --> 00:03:53.800 align:middle line:-1
我们可以将该模型当做特征提取器

00:03:53.867 --> 00:03:56.670 align:middle line:-1
这可以给我们一个特征向量

00:03:56.737 --> 00:03:58.305 align:middle line:-1
它是我们图像中物体的数字描述

00:03:59.373 --> 00:04:02.242 align:middle line:-2
现在你引入自己的数据
我们使用你的标签数据训练该集合

