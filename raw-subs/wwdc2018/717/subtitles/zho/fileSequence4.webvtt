WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:03:59.373 --> 00:04:02.242 align:middle line:-2
现在你引入自己的数据
我们使用你的标签数据训练该集合

00:04:02.309 --> 00:04:05.078 align:middle line:0
我们称之为最后一层
即真正的分类器

00:04:05.579 --> 00:04:09.183 align:middle line:0
最终输出你的自定义模型

00:04:11.285 --> 00:04:14.588 align:middle line:-1
我提到了这个大型的首次预训练模型

00:04:15.322 --> 00:04:17.257 align:middle line:-2
本次演讲中
带来Vision的新特性

00:04:17.324 --> 00:04:20.127 align:middle line:-2
我们称之为面向场景的
Vision FeaturePrint

00:04:20.961 --> 00:04:22.696 align:middle line:-1
它可在Create ML中使用

00:04:23.363 --> 00:04:25.866 align:middle line:-1
并允许你训练图像分类器

00:04:27.668 --> 00:04:30.304 align:middle line:-2
它已经在一个非常大的
数据集上进行过训练

00:04:31.371 --> 00:04:35.042 align:middle line:-1
它能够分类超过一千个类别

00:04:35.309 --> 00:04:39.046 align:middle line:-2
这是一个你可以使用的
非常好的发行版

00:04:40.681 --> 00:04:41.782 align:middle line:-1
我们已经使用过它了

00:04:41.849 --> 00:04:44.484 align:middle line:-2
在过去三年中
你可能已经在Photos中见过的

00:04:44.551 --> 00:04:48.522 align:middle line:-2
一些面向用户的功能
实际上它们在底层使用了此模型

00:04:49.923 --> 00:04:53.493 align:middle line:-2
我们也将继续改进该模型
但也有一点需要注意

00:04:53.560 --> 00:04:55.329 align:middle line:-1
我想在此强调一下

00:04:56.630 --> 00:04:59.333 align:middle line:-1
当我们推出该模型的新版本时

00:04:59.399 --> 00:05:01.768 align:middle line:-1
你不一定会自动获得它的改进

