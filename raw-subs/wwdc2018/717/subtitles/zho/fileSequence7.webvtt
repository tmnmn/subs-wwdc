WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:06:57.885 --> 00:07:01.855 align:middle line:-2
使用我们的
Vision FeaturePrint

00:07:01.922 --> 00:07:04.124 align:middle line:-1
并向我们返回分类

00:07:07.227 --> 00:07:09.997 align:middle line:-2
这就是我们需要了解的
关于训练的东西

00:07:10.864 --> 00:07:14.101 align:middle line:-1
但我说过当我们处理app时

00:07:14.168 --> 00:07:15.636 align:middle line:-1
还有一些注意事项

00:07:16.637 --> 00:07:17.471 align:middle line:-1
所以

00:07:18.605 --> 00:07:20.474 align:middle line:-1
首先 我们只想

00:07:20.541 --> 00:07:22.676 align:middle line:-1
在必要的时候才运行我们的分类器

00:07:24.444 --> 00:07:26.513 align:middle line:-1
分类器是深度卷积网络

00:07:26.580 --> 00:07:28.615 align:middle line:-1
它是计算密集型的

00:07:28.682 --> 00:07:32.219 align:middle line:-2
所以当我们运行它时
它肯定会用掉

00:07:32.452 --> 00:07:35.155 align:middle line:-1
CPU和GPU上运行的一些电子

00:07:35.422 --> 00:07:38.058 align:middle line:-2
所以除非你真的需要
否则你不想使用它

00:07:38.892 --> 00:07:41.862 align:middle line:-1
在我稍后演示的例子中

00:07:42.696 --> 00:07:46.366 align:middle line:-2
我实际上只想在用户
真正看一件物体时才进行分类

00:07:46.433 --> 00:07:48.235 align:middle line:-1
而不是在相机四处移动时

00:07:50.037 --> 00:07:53.073 align:middle line:-2
所以我问的问题是
“我拿稳相机了吗？”

00:07:53.140 --> 00:07:55.075 align:middle line:-1
然后我才运行我的分类器

00:07:56.009 --> 00:07:59.847 align:middle line:-2
我该怎么做？
我可以通过Vision进行配准

