WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:18:59.339 --> 00:19:02.176 align:middle line:-2
在这种情况下 我没使用
Core ML的代码完成功能

00:19:02.242 --> 00:19:05.479 align:middle line:-2
因为这是我的app中使用的
唯一一行Core ML代码

00:19:05.546 --> 00:19:09.249 align:middle line:-1
它允许我进行自定义类型的错误处理

00:19:09.316 --> 00:19:12.619 align:middle line:-2
但你也可以选择使用
Core ML中的代码完成功能

00:19:12.686 --> 00:19:16.857 align:middle line:-2
两者都绝对有效
我由它创建我的Vision模型

00:19:17.124 --> 00:19:20.460 align:middle line:-2
Vision Core ML模型
以及请求

00:19:20.661 --> 00:19:23.697 align:middle line:-1
同样 当请求返回时

00:19:23.764 --> 00:19:26.233 align:middle line:-1
这意味着会执行我的完成处理程序

00:19:26.733 --> 00:19:30.838 align:middle line:-2
我只是检查
我得到的是什么样的分类

00:19:31.705 --> 00:19:33.740 align:middle line:-1
然后我在这里设置此阈值

00:19:34.141 --> 00:19:37.277 align:middle line:-1
这是我凭经验设定的置信度目标

00:19:37.344 --> 00:19:42.316 align:middle line:-2
我使用的是0.98
即有98%的信心它是正确的

00:19:43.383 --> 00:19:44.685 align:middle line:-1
为什么我要这样做？

00:19:45.185 --> 00:19:46.854 align:middle line:-1
这允许我过滤掉

00:19:46.920 --> 00:19:49.256 align:middle line:-2
当我在看某物体时
不太确定那是什么的情况

00:19:49.323 --> 00:19:51.491 align:middle line:-1
我们稍后会看到这是什么意思

00:19:52.893 --> 00:19:54.595 align:middle line:-1
现在我准备好了所有的请求

00:19:55.562 --> 00:19:57.764 align:middle line:-1
当我真正想要执行它们的时候

00:19:57.831 --> 00:19:59.466 align:middle line:-1
我在这里创建了一个小函数

00:19:59.533 --> 00:20:01.902 align:middle line:-1
它的作用是分析当前图像

