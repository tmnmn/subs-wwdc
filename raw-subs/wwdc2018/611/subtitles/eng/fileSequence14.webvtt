WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:13:59.906 --> 00:14:01.426 A:middle
post-processing, as we talked

00:14:01.516 --> 00:14:02.706 A:middle
about a few slides before.

00:14:02.706 --> 00:14:07.316 A:middle
After that, frames scanned out

00:14:07.646 --> 00:14:08.576 A:middle
from memory to [inaudible] in

00:14:08.636 --> 00:14:09.466 A:middle
the headset.

00:14:09.596 --> 00:14:12.266 A:middle
This transfer takes additional

00:14:12.266 --> 00:14:15.226 A:middle
frame as all pixels need to be

00:14:15.376 --> 00:14:17.376 A:middle
updated before image can be

00:14:17.436 --> 00:14:17.986 A:middle
presented.

00:14:19.296 --> 00:14:23.436 A:middle
Once all pixels are updated,

00:14:23.566 --> 00:14:25.686 A:middle
[inaudible] and user can see a

00:14:25.686 --> 00:14:26.106 A:middle
frame.

00:14:27.246 --> 00:14:28.346 A:middle
So as you can see from the

00:14:28.346 --> 00:14:29.846 A:middle
moment the application receives

00:14:29.926 --> 00:14:32.036 A:middle
pauses, to the moment image is

00:14:32.036 --> 00:14:34.476 A:middle
really projected, it takes about

00:14:34.566 --> 00:14:35.896 A:middle
25 milliseconds.

00:14:35.976 --> 00:14:39.556 A:middle
That is why application receives

00:14:39.686 --> 00:14:41.346 A:middle
pauses that are already

00:14:41.346 --> 00:14:43.296 A:middle
predicted into the future, to

00:14:43.546 --> 00:14:45.116 A:middle
the moment when photons will be

00:14:45.116 --> 00:14:47.806 A:middle
emitted, so that the rendered

00:14:47.896 --> 00:14:49.546 A:middle
image is matching the user

00:14:49.636 --> 00:14:49.946 A:middle
pause.

00:14:50.066 --> 00:14:54.336 A:middle
And this cascade of events

00:14:54.416 --> 00:14:56.046 A:middle
overlapping with previous and

00:14:56.046 --> 00:14:58.486 A:middle
next frame is creating our frame

00:14:58.516 --> 00:14:59.436 A:middle
basing diagram.

00:14:59.436 --> 00:15:02.096 A:middle
As you can see, in case of the

