WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:31:58.876 --> 00:32:00.146 A:middle
to worry about tokenization

00:32:00.146 --> 00:32:01.286 A:middle
feature extraction or anything

00:32:01.286 --> 00:32:01.496 A:middle
else.

00:32:01.706 --> 00:32:03.236 A:middle
In fact, you don't have to write

00:32:03.236 --> 00:32:04.376 A:middle
a single line of code because

00:32:04.636 --> 00:32:06.446 A:middle
Natural Language does all of

00:32:06.446 --> 00:32:07.036 A:middle
that for you.

00:32:07.356 --> 00:32:08.916 A:middle
You just focus on your app and

00:32:08.916 --> 00:32:10.296 A:middle
your task and simply drag and

00:32:10.296 --> 00:32:11.176 A:middle
drop the model in.

00:32:11.636 --> 00:32:15.026 A:middle
The other aspect of Natural

00:32:15.026 --> 00:32:16.226 A:middle
Language as I mentioned before

00:32:16.296 --> 00:32:17.856 A:middle
is it's optimized for Apple

00:32:17.856 --> 00:32:19.916 A:middle
hardware and for model sizes.

00:32:20.036 --> 00:32:21.626 A:middle
So let's look at this through a

00:32:21.626 --> 00:32:22.586 A:middle
couple of examples.

00:32:23.276 --> 00:32:25.066 A:middle
So Doug talked about named

00:32:25.066 --> 00:32:26.556 A:middle
entity recognition and chunking,

00:32:27.096 --> 00:32:28.146 A:middle
and here are two different

00:32:28.146 --> 00:32:28.746 A:middle
benchmarks.

00:32:28.746 --> 00:32:30.876 A:middle
So these are models that we

00:32:30.876 --> 00:32:32.726 A:middle
built using an open source tool

00:32:32.726 --> 00:32:34.396 A:middle
kit called CRF Suite, and

00:32:34.396 --> 00:32:35.336 A:middle
through Natural Language.

00:32:35.716 --> 00:32:36.706 A:middle
The models were built from

00:32:36.776 --> 00:32:38.856 A:middle
identical training data and

00:32:38.856 --> 00:32:40.346 A:middle
tested on identical test data.

00:32:40.856 --> 00:32:41.906 A:middle
The same sort of features were

00:32:41.906 --> 00:32:42.306 A:middle
used.

00:32:42.496 --> 00:32:43.836 A:middle
The accuracy obtained by both

00:32:43.836 --> 00:32:45.066 A:middle
these models is the same.

00:32:45.546 --> 00:32:47.316 A:middle
But you look at the model sizes

00:32:47.316 --> 00:32:48.496 A:middle
that Natural Language is able to

00:32:48.496 --> 00:32:48.886 A:middle
generate.

00:32:49.446 --> 00:32:50.926 A:middle
It's simply just about 1.4

00:32:50.926 --> 00:32:53.076 A:middle
megabytes of data size, model

00:32:53.076 --> 00:32:53.936 A:middle
size for named entity

00:32:53.936 --> 00:32:55.576 A:middle
recognition and 1.8 megabytes

00:32:55.576 --> 00:32:56.076 A:middle
for chunking.

00:32:56.576 --> 00:32:57.916 A:middle
That saves you an enormous

00:32:57.916 --> 00:32:59.296 A:middle
amount of space within your app

00:32:59.296 --> 00:33:00.056 A:middle
to do other things.

