WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:14:57.231 --> 00:15:00.367 align:middle line:0
推理就是当你在运行时

00:15:00.434 --> 00:15:04.538 align:middle line:0
将该模型整合到你的app中后
所发生的事情

00:15:04.605 --> 00:15:07.407 align:middle line:0
当它遇到来自用户的一些数据时

00:15:07.808 --> 00:15:09.176 align:middle line:0
它会分析这些数据

00:15:09.243 --> 00:15:11.311 align:middle line:0
并预测适当的标签

00:15:12.012 --> 00:15:13.847 align:middle line:0
让我们看看这些阶段是如何工作的

00:15:14.948 --> 00:15:18.852 align:middle line:-2
让我们从训练开始
而训练总是从数据开始

00:15:19.419 --> 00:15:23.557 align:middle line:-1
你将你的训练数据输入到

00:15:23.624 --> 00:15:29.429 align:middle line:-2
Playground或脚本
包装器中的Create ML

00:15:30.264 --> 00:15:32.199 align:middle line:-2
如你在Create ML演讲中
所见

00:15:32.633 --> 00:15:34.101 align:middle line:-1
Create ML在底层调用

00:15:34.168 --> 00:15:37.304 align:middle line:-2
Natural Language
框架来进行训练

00:15:38.005 --> 00:15:44.545 align:middle line:-2
其输出的是一个Core ML模型
并已针对设备上的使用进行了优化

00:15:45.979 --> 00:15:48.348 align:middle line:-1
让我们看看这些数据是什么样子的

00:15:49.750 --> 00:15:52.920 align:middle line:-2
Create ML支持
多种不同的数据格式

00:15:53.987 --> 00:15:58.692 align:middle line:-2
在这里我们使用JSON显示数据
因为JSON使事情变得非常清晰

