WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:04:01.186 --> 00:04:03.566 A:middle
Last year, we collaborated with

00:04:03.566 --> 00:04:05.286 A:middle
Google and released the

00:04:05.286 --> 00:04:06.096 A:middle
TensorFlow converter.

00:04:06.096 --> 00:04:08.686 A:middle
So that was exciting.

00:04:10.396 --> 00:04:12.416 A:middle
As you know, TensorFlow is quite

00:04:12.416 --> 00:04:14.216 A:middle
popular with researchers who try

00:04:14.216 --> 00:04:16.586 A:middle
out new layers so we recently

00:04:16.586 --> 00:04:18.336 A:middle
added support for custom layers

00:04:18.555 --> 00:04:19.396 A:middle
into the converter.

00:04:20.776 --> 00:04:22.976 A:middle
And TensorFlow recently released

00:04:22.976 --> 00:04:25.236 A:middle
support for quantization during

00:04:25.376 --> 00:04:27.506 A:middle
training and that's Core ML 2

00:04:27.506 --> 00:04:28.676 A:middle
supports quantization.

00:04:29.086 --> 00:04:30.586 A:middle
This feature will be added soon

00:04:30.586 --> 00:04:31.196 A:middle
to the converter.

00:04:33.186 --> 00:04:34.616 A:middle
Another exciting partnership we

00:04:34.616 --> 00:04:37.286 A:middle
had was with Facebook and

00:04:37.326 --> 00:04:37.836 A:middle
Prisma.

00:04:38.336 --> 00:04:40.406 A:middle
And this resulted in the ONNX

00:04:40.406 --> 00:04:40.866 A:middle
converter.

00:04:42.216 --> 00:04:43.646 A:middle
The nice thing about ONNX is

00:04:43.646 --> 00:04:48.056 A:middle
that now you have access to a

00:04:48.056 --> 00:04:49.376 A:middle
bunch of different training

00:04:49.376 --> 00:04:50.946 A:middle
libraries that can all be

00:04:50.946 --> 00:04:53.106 A:middle
converted to Core ML using the

00:04:53.106 --> 00:04:54.136 A:middle
new ONNX converter.

00:04:54.136 --> 00:04:58.956 A:middle
So that was a quick wrap-up of

00:04:58.956 --> 00:05:00.446 A:middle
Core ML Tools ecosystem.

