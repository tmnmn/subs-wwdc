WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:09:59.936 --> 00:10:01.116 A:middle
using the amount of data that

00:10:01.166 --> 00:10:01.446 A:middle
you have.

00:10:03.576 --> 00:10:05.426 A:middle
This results in faster training

00:10:05.516 --> 00:10:05.656 A:middle
times.

00:10:06.176 --> 00:10:07.306 A:middle
And for developers that we've

00:10:07.346 --> 00:10:08.936 A:middle
worked with, we've seen them go

00:10:09.596 --> 00:10:12.996 A:middle
from hours of training down to

00:10:12.996 --> 00:10:14.576 A:middle
minutes for thousands of images

00:10:15.056 --> 00:10:16.756 A:middle
or for small data sets, even

00:10:16.826 --> 00:10:17.166 A:middle
seconds.

00:10:19.886 --> 00:10:21.126 A:middle
This also results in much

00:10:21.296 --> 00:10:23.026 A:middle
smaller models going from

00:10:23.026 --> 00:10:25.156 A:middle
hundreds of megabytes down to

00:10:25.606 --> 00:10:26.756 A:middle
just a few megabytes for

00:10:26.756 --> 00:10:28.426 A:middle
thousands of images or even

00:10:28.426 --> 00:10:28.896 A:middle
kilobytes.

00:10:32.076 --> 00:10:34.416 A:middle
The goal of Create ML is to

00:10:34.416 --> 00:10:35.966 A:middle
abstract much of this and make

00:10:35.966 --> 00:10:37.646 A:middle
it simple and easy to use.

00:10:38.286 --> 00:10:39.786 A:middle
But to prove it, let's take a

00:10:39.786 --> 00:10:40.396 A:middle
look at a demo.

00:10:47.396 --> 00:10:49.356 A:middle
First, to set up the problem, I

00:10:49.446 --> 00:10:51.066 A:middle
started by running an app that's

00:10:51.126 --> 00:10:52.546 A:middle
using a state-of-the-art image

00:10:52.626 --> 00:10:54.286 A:middle
classification model that's

00:10:54.286 --> 00:10:55.166 A:middle
already in the industry.

00:10:56.326 --> 00:10:57.486 A:middle
This one, though, is quite

00:10:57.526 --> 00:10:57.766 A:middle
large.

00:10:57.766 --> 00:10:59.446 A:middle
It's 100 megabytes in our app.

