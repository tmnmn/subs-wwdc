WEBVTT
X-TIMESTAMP-MAP=MPEGTS:181083,LOCAL:00:00:00.000

00:16:59.666 --> 00:17:01.396 A:middle
training the model by specifying

00:17:01.496 --> 00:17:02.726 A:middle
how our training data was laid

00:17:02.726 --> 00:17:02.926 A:middle
out.

00:17:04.205 --> 00:17:05.346 A:middle
We can then evaluate on the

00:17:05.415 --> 00:17:07.996 A:middle
testing data and finally save ML

00:17:07.996 --> 00:17:08.306 A:middle
model.

00:17:11.576 --> 00:17:12.596 A:middle
If you want to automate this,

00:17:13.006 --> 00:17:14.215 A:middle
you can also turn these into

00:17:14.326 --> 00:17:16.106 A:middle
scripts, which is a very popular

00:17:16.106 --> 00:17:17.836 A:middle
way of saving what you've done

00:17:17.836 --> 00:17:19.215 A:middle
and re-running it whenever.

00:17:21.746 --> 00:17:22.896 A:middle
You can then change permissions

00:17:22.896 --> 00:17:24.766 A:middle
on the file and run them like

00:17:24.866 --> 00:17:25.086 A:middle
so.

00:17:26.056 --> 00:17:27.806 A:middle
Or for other workflows, you can

00:17:27.806 --> 00:17:29.996 A:middle
always use Swift command line

00:17:29.996 --> 00:17:30.126 A:middle
[inaudible].

00:17:30.126 --> 00:17:33.246 A:middle
So we've seen today how to train

00:17:33.246 --> 00:17:34.496 A:middle
image classification models

00:17:35.016 --> 00:17:36.176 A:middle
using a few different workflows.

00:17:36.176 --> 00:17:38.496 A:middle
But next, I'd like to pass it

00:17:38.496 --> 00:17:40.576 A:middle
off to Tao to talk about natural

00:17:40.576 --> 00:17:40.976 A:middle
language.

00:17:41.476 --> 00:17:41.766 A:middle
Thank you.

00:17:42.516 --> 00:17:49.876 A:middle
[ Applause ]

00:17:50.376 --> 00:17:53.546 A:middle
&gt;&gt; Thank you, Lizi.

00:17:54.636 --> 00:17:55.336 A:middle
Hello everyone.

00:17:55.526 --> 00:17:56.466 A:middle
My name is Tao.

00:17:56.466 --> 00:17:58.416 A:middle
I'm an engineer here at Apple

00:17:58.686 --> 00:18:00.086 A:middle
working on the Core ML team.

